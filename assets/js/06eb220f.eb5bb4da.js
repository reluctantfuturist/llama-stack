"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5290],{14795:(e,t,n)=>{n.d(t,{A:()=>b});n(96540);var i=n(34164),r=n(26972),s=n(28774),a=n(53465),c=n(16654),o=n(21312),l=n(51107);const d={cardContainer:"cardContainer_fWXF",cardTitle:"cardTitle_rnsV",cardDescription:"cardDescription_PWke"};var m=n(74848);function u(e){var t=e.className,n=e.href,r=e.children;return(0,m.jsx)(s.default,{href:n,className:(0,i.A)("card padding--lg",d.cardContainer,t),children:r})}function p(e){var t=e.className,n=e.href,r=e.icon,s=e.title,a=e.description;return(0,m.jsxs)(u,{href:n,className:t,children:[(0,m.jsxs)(l.default,{as:"h2",className:(0,i.A)("text--truncate",d.cardTitle),title:s,children:[r," ",s]}),a&&(0,m.jsx)("p",{className:(0,i.A)("text--truncate",d.cardDescription),title:a,children:a})]})}function f(e){var t,n,i=e.item,s=(0,r.Nr)(i),c=(n=(0,a.W)().selectMessage,function(e){return n(e,(0,o.translate)({message:"1 item|{count} items",id:"theme.docs.DocCard.categoryDescription.plurals",description:"The default description for a category card in the generated index about how many items this category includes"},{count:e}))});return s?(0,m.jsx)(p,{className:i.className,href:s,icon:"\ud83d\uddc3\ufe0f",title:i.label,description:null!=(t=i.description)?t:c(i.items.length)}):null}function h(e){var t,n,i=e.item,s=(0,c.A)(i.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",a=(0,r.cC)(null!=(t=i.docId)?t:void 0);return(0,m.jsx)(p,{className:i.className,href:i.href,icon:s,title:i.label,description:null!=(n=i.description)?n:null==a?void 0:a.description})}function g(e){var t=e.item;switch(t.type){case"link":return(0,m.jsx)(h,{item:t});case"category":return(0,m.jsx)(f,{item:t});default:throw new Error("unknown item type "+JSON.stringify(t))}}const x={docCardListItem:"docCardListItem_W1sv"};function j(e){var t=e.className,n=(0,r.a4)();return(0,m.jsx)(b,{items:n,className:t})}function v(e){var t=e.item;return(0,m.jsx)("article",{className:(0,i.A)(x.docCardListItem,"col col--6"),children:(0,m.jsx)(g,{item:t})})}function b(e){var t=e.items,n=e.className;if(!t)return(0,m.jsx)(j,Object.assign({},e));var s=(0,r.d1)(t);return(0,m.jsx)("section",{className:(0,i.A)("row",n),children:s.map(function(e,t){return(0,m.jsx)(v,{item:e},t)})})}},38555:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>m});const i=JSON.parse('{"id":"api/inference","title":"Llama Stack Inference API for generating completions, chat completions, and embeddings.","description":"Llama Stack Inference API for generating completions, chat completions, and embeddings.","source":"@site/docs/api/inference.tag.mdx","sourceDirName":"api","slug":"/api/inference","permalink":"/docs/api/inference","draft":false,"unlisted":false,"editUrl":null,"tags":[],"version":"current","frontMatter":{"id":"inference","title":"Llama Stack Inference API for generating completions, chat completions, and embeddings.","description":"Llama Stack Inference API for generating completions, chat completions, and embeddings.","custom_edit_url":null},"sidebar":"apiSidebar","previous":{"title":"Returns the contents of the specified file.","permalink":"/docs/api/openai-retrieve-file-content"},"next":{"title":"Generate chat completions for a batch of messages using the specified model.","permalink":"/docs/api/batch-chat-completion"}}');var r=n(74848),s=n(28453),a=n(14795),c=n(83262);const o={id:"inference",title:"Llama Stack Inference API for generating completions, chat completions, and embeddings.",description:"Llama Stack Inference API for generating completions, chat completions, and embeddings.",custom_edit_url:null},l=void 0,d={},m=[];function u(e){const t={li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.p,{children:"This API provides the raw interface to the underlying models. Two kinds of models are supported:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:'LLM models: these models generate "raw" and "chat" (conversational) completions.'}),"\n",(0,r.jsx)(t.li,{children:"Embedding models: these models generate embeddings to be used for semantic search."}),"\n"]}),"\n","\n",(0,r.jsx)(a.A,{items:(0,c.useCurrentSidebarCategory)().items})]})}function p(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}}}]);