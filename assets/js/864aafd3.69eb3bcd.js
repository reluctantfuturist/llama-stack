"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7542],{4865:(e,n,a)=>{a.d(n,{A:()=>m});var t=a(96540),l=a(34164),s=a(23104),r=a(47751),i=a(92303);const o={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=a(74848);function d(e){var n=e.className,a=e.block,t=e.selectedValue,r=e.selectValue,i=e.tabValues,d=[],u=(0,s.a_)().blockElementScrollPositionUntilNextRender,p=function(e){var n=e.currentTarget,a=d.indexOf(n),l=i[a].value;l!==t&&(u(n),r(l))},m=function(e){var n,a=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":var t,l=d.indexOf(e.currentTarget)+1;a=null!=(t=d[l])?t:d[0];break;case"ArrowLeft":var s,r=d.indexOf(e.currentTarget)-1;a=null!=(s=d[r])?s:d[d.length-1]}null==(n=a)||n.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.A)("tabs",{"tabs--block":a},n),children:i.map(function(e){var n=e.value,a=e.label,s=e.attributes;return(0,c.jsx)("li",Object.assign({role:"tab",tabIndex:t===n?0:-1,"aria-selected":t===n,ref:function(e){d.push(e)},onKeyDown:m,onClick:p},s,{className:(0,l.A)("tabs__item",o.tabItem,null==s?void 0:s.className,{"tabs__item--active":t===n}),children:null!=a?a:n}),n)})})}function u(e){var n=e.lazy,a=e.children,s=e.selectedValue,r=(Array.isArray(a)?a:[a]).filter(Boolean);if(n){var i=r.find(function(e){return e.props.value===s});return i?(0,t.cloneElement)(i,{className:(0,l.A)("margin-top--md",i.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:r.map(function(e,n){return(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==s})})})}function p(e){var n=(0,r.u)(e);return(0,c.jsxs)("div",{className:(0,l.A)("tabs-container",o.tabList),children:[(0,c.jsx)(d,Object.assign({},n,e)),(0,c.jsx)(u,Object.assign({},n,e))]})}function m(e){var n=(0,i.default)();return(0,c.jsx)(p,Object.assign({},e,{children:(0,r.v)(e.children)}),String(n))}},62503:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"deploying/kubernetes","title":"Kubernetes Deployment Guide","description":"Deploy Llama Stack on Kubernetes clusters with vLLM inference service","source":"@site/docs/deploying/kubernetes.mdx","sourceDirName":"deploying","slug":"/deploying/kubernetes","permalink":"/docs/deploying/kubernetes","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/deploying/kubernetes.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Kubernetes Deployment Guide","description":"Deploy Llama Stack on Kubernetes clusters with vLLM inference service","sidebar_label":"Kubernetes","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Overview","permalink":"/docs/deploying/"},"next":{"title":"Overview","permalink":"/docs/contributing/"}}');var l=a(74848),s=a(28453);a(4865),a(19365);const r={title:"Kubernetes Deployment Guide",description:"Deploy Llama Stack on Kubernetes clusters with vLLM inference service",sidebar_label:"Kubernetes",sidebar_position:2},i="Kubernetes Deployment Guide",o={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Local Kubernetes Setup",id:"local-kubernetes-setup",level:3},{value:"Quick Deployment",id:"quick-deployment",level:2},{value:"Step 1: Create Storage and Secrets",id:"step-1-create-storage-and-secrets",level:3},{value:"Step 2: Deploy vLLM Server",id:"step-2-deploy-vllm-server",level:3},{value:"Step 3: Configure Llama Stack",id:"step-3-configure-llama-stack",level:3},{value:"Step 4: Deploy Llama Stack Server",id:"step-4-deploy-llama-stack-server",level:3},{value:"Step 5: Test Deployment",id:"step-5-test-deployment",level:3},{value:"AWS EKS Deployment",id:"aws-eks-deployment",level:2},{value:"Prerequisites",id:"prerequisites-1",level:3},{value:"Automated Deployment",id:"automated-deployment",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Related Resources",id:"related-resources",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"kubernetes-deployment-guide",children:"Kubernetes Deployment Guide"})}),"\n",(0,l.jsx)(n.p,{children:"Deploy Llama Stack and vLLM servers in a Kubernetes cluster instead of running them locally. This guide covers both local development with Kind and production deployment on AWS EKS."}),"\n",(0,l.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,l.jsx)(n.h3,{id:"local-kubernetes-setup",children:"Local Kubernetes Setup"}),"\n",(0,l.jsx)(n.p,{children:"Create a local Kubernetes cluster via Kind:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"kind create cluster --image kindest/node:v1.32.0 --name llama-stack-test\n"})}),"\n",(0,l.jsx)(n.p,{children:"Set your Hugging Face token:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'export HF_TOKEN=$(echo -n "your-hf-token" | base64)\n'})}),"\n",(0,l.jsx)(n.h2,{id:"quick-deployment",children:"Quick Deployment"}),"\n",(0,l.jsx)(n.h3,{id:"step-1-create-storage-and-secrets",children:"Step 1: Create Storage and Secrets"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: vllm-models\nspec:\n  accessModes:\n    - ReadWriteOnce\n  volumeMode: Filesystem\n  resources:\n    requests:\n      storage: 50Gi\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hf-token-secret\ntype: Opaque\ndata:\n  token: $HF_TOKEN\nEOF\n"})}),"\n",(0,l.jsx)(n.h3,{id:"step-2-deploy-vllm-server",children:"Step 2: Deploy vLLM Server"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:'cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vllm-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vllm\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: vllm\n    spec:\n      containers:\n      - name: vllm\n        image: vllm/vllm-openai:latest\n        command: ["/bin/sh", "-c"]\n        args: ["vllm serve meta-llama/Llama-3.2-1B-Instruct"]\n        env:\n        - name: HUGGING_FACE_HUB_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: hf-token-secret\n              key: token\n        ports:\n          - containerPort: 8000\n        volumeMounts:\n          - name: llama-storage\n            mountPath: /root/.cache/huggingface\n      volumes:\n      - name: llama-storage\n        persistentVolumeClaim:\n          claimName: vllm-models\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: vllm-server\nspec:\n  selector:\n    app.kubernetes.io/name: vllm\n  ports:\n  - protocol: TCP\n    port: 8000\n    targetPort: 8000\n  type: ClusterIP\nEOF\n'})}),"\n",(0,l.jsx)(n.h3,{id:"step-3-configure-llama-stack",children:"Step 3: Configure Llama Stack"}),"\n",(0,l.jsx)(n.p,{children:"Update your run configuration:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:"providers:\n  inference:\n  - provider_id: vllm\n    provider_type: remote::vllm\n    config:\n      url: http://vllm-server.default.svc.cluster.local:8000/v1\n      max_tokens: 4096\n      api_token: fake\n"})}),"\n",(0,l.jsx)(n.p,{children:"Build container image:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"tmp_dir=$(mktemp -d) && cat >$tmp_dir/Containerfile.llama-stack-run-k8s <<EOF\nFROM distribution-myenv:dev\nRUN apt-get update && apt-get install -y git\nRUN git clone https://github.com/meta-llama/llama-stack.git /app/llama-stack-source\nADD ./vllm-llama-stack-run-k8s.yaml /app/config.yaml\nEOF\npodman build -f $tmp_dir/Containerfile.llama-stack-run-k8s -t llama-stack-run-k8s $tmp_dir\n"})}),"\n",(0,l.jsx)(n.h3,{id:"step-4-deploy-llama-stack-server",children:"Step 4: Deploy Llama Stack Server"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:'cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: llama-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: llama-stack-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: llama-stack\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: llama-stack\n    spec:\n      containers:\n      - name: llama-stack\n        image: localhost/llama-stack-run-k8s:latest\n        imagePullPolicy: IfNotPresent\n        command: ["python", "-m", "llama_stack.core.server.server", "--config", "/app/config.yaml"]\n        ports:\n          - containerPort: 5000\n        volumeMounts:\n          - name: llama-storage\n            mountPath: /root/.llama\n      volumes:\n      - name: llama-storage\n        persistentVolumeClaim:\n          claimName: llama-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: llama-stack-service\nspec:\n  selector:\n    app.kubernetes.io/name: llama-stack\n  ports:\n  - protocol: TCP\n    port: 5000\n    targetPort: 5000\n  type: ClusterIP\nEOF\n'})}),"\n",(0,l.jsx)(n.h3,{id:"step-5-test-deployment",children:"Step 5: Test Deployment"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'# Port forward and test\nkubectl port-forward service/llama-stack-service 5000:5000\nllama-stack-client --endpoint http://localhost:5000 inference chat-completion --message "hello, what model are you?"\n'})}),"\n",(0,l.jsx)(n.h2,{id:"aws-eks-deployment",children:"AWS EKS Deployment"}),"\n",(0,l.jsx)(n.h3,{id:"prerequisites-1",children:"Prerequisites"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Set up an ",(0,l.jsx)(n.a,{href:"https://docs.aws.amazon.com/eks/latest/userguide/getting-started.html",children:"EKS cluster"})]}),"\n",(0,l.jsxs)(n.li,{children:["Create a ",(0,l.jsx)(n.a,{href:"https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/creating-an-oauth-app",children:"GitHub OAuth app"})]}),"\n",(0,l.jsxs)(n.li,{children:["Set authorization callback URL to ",(0,l.jsx)(n.code,{children:"http://<your-llama-stack-ui-url>/api/auth/callback/"})]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"automated-deployment",children:"Automated Deployment"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"export HF_TOKEN=<your-huggingface-token>\nexport GITHUB_CLIENT_ID=<your-github-client-id>\nexport GITHUB_CLIENT_SECRET=<your-github-client-secret>\nexport LLAMA_STACK_UI_URL=<your-llama-stack-ui-url>\n\ncd docs/source/distributions/eks\n./apply.sh\n"})}),"\n",(0,l.jsx)(n.p,{children:"This script will:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Set up default storage class for AWS EKS"}),"\n",(0,l.jsx)(n.li,{children:"Deploy Llama Stack server in Kubernetes pods and services"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Check pod status:"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"kubectl get pods -l app.kubernetes.io/name=vllm\nkubectl logs -l app.kubernetes.io/name=vllm\n"})}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Test service connectivity:"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- curl http://vllm-server:8000/v1/models\n"})}),"\n",(0,l.jsx)(n.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"./index",children:"Deployment Overview"})})," - Overview of deployment options"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/docs/distributions",children:"Distributions"})})," - Understanding Llama Stack distributions"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/docs/distributions/configuration",children:"Configuration"})})," - Detailed configuration options"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(d,{...e})}):d(e)}}}]);