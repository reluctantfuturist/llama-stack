"use strict";(self.webpackChunkdocusaurus_template_openapi_docs=self.webpackChunkdocusaurus_template_openapi_docs||[]).push([[6903],{28453:(e,t,a)=>{a.d(t,{R:()=>s,x:()=>o});var i=a(96540);const n={},r=i.createContext(n);function s(e){const t=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:s(e.components),i.createElement(r.Provider,{value:t},e.children)}},68189:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"intro","title":"Welcome to Llama Stack","description":"Llama Stack is the open-source framework for building generative AI applications","source":"@site/docs/intro.mdx","sourceDirName":".","slug":"/intro","permalink":"/llama-stack/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/intro.mdx","tags":[{"inline":true,"label":"getting-started","permalink":"/llama-stack/docs/tags/getting-started"},{"inline":true,"label":"overview","permalink":"/llama-stack/docs/tags/overview"}],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Welcome to Llama Stack","description":"Llama Stack is the open-source framework for building generative AI applications","sidebar_label":"Intro","tags":["getting-started","overview"]},"sidebar":"tutorialSidebar","next":{"title":"Quickstart","permalink":"/llama-stack/docs/getting-started/"}}');var n=a(74848),r=a(28453);const s={sidebar_position:1,title:"Welcome to Llama Stack",description:"Llama Stack is the open-source framework for building generative AI applications",sidebar_label:"Intro",tags:["getting-started","overview"]},o="Welcome to Llama Stack",l={},c=[{value:"What is Llama Stack?",id:"what-is-llama-stack",level:2},{value:"How does Llama Stack work?",id:"how-does-llama-stack-work",level:2},{value:"Quick Links",id:"quick-links",level:2},{value:"Rich Ecosystem Support",id:"rich-ecosystem-support",level:2},{value:"Get Started Today",id:"get-started-today",level:2}];function d(e){const t={a:"a",admonition:"admonition",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"welcome-to-llama-stack",children:"Welcome to Llama Stack"})}),"\n",(0,n.jsx)(t.p,{children:"Llama Stack is the open-source framework for building generative AI applications."}),"\n",(0,n.jsx)(t.admonition,{title:"Llama 4 is here!",type:"tip",children:(0,n.jsxs)(t.p,{children:["Check out ",(0,n.jsx)(t.a,{href:"https://colab.research.google.com/github/meta-llama/llama-stack/blob/main/docs/getting_started_llama4.ipynb",children:"Getting Started with Llama 4"})]})}),"\n",(0,n.jsx)(t.admonition,{title:"News",type:"tip",children:(0,n.jsxs)(t.p,{children:["Llama Stack is now available! See the ",(0,n.jsx)(t.a,{href:"https://github.com/meta-llama/llama-stack/releases",children:"release notes"})," for more details."]})}),"\n",(0,n.jsx)(t.h2,{id:"what-is-llama-stack",children:"What is Llama Stack?"}),"\n",(0,n.jsx)(t.p,{children:"Llama Stack defines and standardizes the core building blocks needed to bring generative AI applications to market. It provides a unified set of APIs with implementations from leading service providers, enabling seamless transitions between development and production environments. More specifically, it provides:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Unified API layer"})," for Inference, RAG, Agents, Tools, Safety, Evals, and Telemetry."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Plugin architecture"})," to support the rich ecosystem of implementations of the different APIs in different environments like local development, on-premises, cloud, and mobile."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Prepackaged verified distributions"})," which offer a one-stop solution for developers to get started quickly and reliably in any environment"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Multiple developer interfaces"})," like CLI and SDKs for Python, Node, iOS, and Android"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Standalone applications"})," as examples for how to build production-grade AI applications with Llama Stack"]}),"\n"]}),"\n",(0,n.jsx)("img",{src:"/img/llama-stack.png",alt:"Llama Stack",width:"400px"}),"\n",(0,n.jsx)(t.p,{children:'Our goal is to provide pre-packaged implementations (aka "distributions") which can be run in a variety of deployment environments. LlamaStack can assist you in your entire app development lifecycle - start iterating on local, mobile or desktop and seamlessly transition to on-prem or public cloud deployments. At every point in this transition, the same set of APIs and the same developer experience is available.'}),"\n",(0,n.jsx)(t.h2,{id:"how-does-llama-stack-work",children:"How does Llama Stack work?"}),"\n",(0,n.jsx)(t.p,{children:"Llama Stack consists of a server (with multiple pluggable API providers) and Client SDKs meant to be used in your applications. The server can be run in a variety of environments, including local (inline) development, on-premises, and cloud. The client SDKs are available for Python, Swift, Node, and Kotlin."}),"\n",(0,n.jsx)(t.h2,{id:"quick-links",children:"Quick Links"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["Ready to build? Check out the ",(0,n.jsx)(t.a,{href:"https://llama-stack.readthedocs.io/en/latest/getting_started/index.html",children:"Getting Started Guide"})," to get started."]}),"\n",(0,n.jsxs)(t.li,{children:["Want to contribute? See the ",(0,n.jsx)(t.a,{href:"https://github.com/meta-llama/llama-stack/blob/main/CONTRIBUTING.md",children:"Contributing Guide"}),"."]}),"\n",(0,n.jsxs)(t.li,{children:["Explore ",(0,n.jsx)(t.a,{href:"https://github.com/meta-llama/llama-stack-apps",children:"Example Applications"})," built with Llama Stack."]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"rich-ecosystem-support",children:"Rich Ecosystem Support"}),"\n",(0,n.jsx)(t.p,{children:"Llama Stack provides adapters for popular providers across all API categories:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Inference"}),": Meta Reference, Ollama, Fireworks, Together, NVIDIA, vLLM, AWS Bedrock, OpenAI, Anthropic, and more"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Vector Databases"}),": FAISS, Chroma, Milvus, Postgres, Weaviate, Qdrant, and others"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Safety"}),": Llama Guard, Prompt Guard, Code Scanner, AWS Bedrock"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Training & Evaluation"}),": HuggingFace, TorchTune, NVIDIA NEMO"]}),"\n"]}),"\n",(0,n.jsx)(t.admonition,{title:"Provider Details",type:"info",children:(0,n.jsxs)(t.p,{children:["For complete provider compatibility and setup instructions, see our ",(0,n.jsx)(t.a,{href:"https://llama-stack.readthedocs.io/en/latest/providers/index.html",children:"Providers Documentation"}),"."]})}),"\n",(0,n.jsx)(t.h2,{id:"get-started-today",children:"Get Started Today"}),"\n",(0,n.jsxs)("div",{style:{display:"flex",gap:"1rem",flexWrap:"wrap",margin:"2rem 0"},children:[(0,n.jsx)("a",{href:"https://llama-stack.readthedocs.io/en/latest/getting_started/index.html",style:{background:"var(--ifm-color-primary)",color:"white",padding:"0.75rem 1.5rem",borderRadius:"0.5rem",textDecoration:"none",fontWeight:"bold"},children:(0,n.jsx)(t.p,{children:"\ud83d\ude80 Quick Start Guide"})}),(0,n.jsx)("a",{href:"https://github.com/meta-llama/llama-stack-apps",style:{border:"2px solid var(--ifm-color-primary)",color:"var(--ifm-color-primary)",padding:"0.75rem 1.5rem",borderRadius:"0.5rem",textDecoration:"none",fontWeight:"bold"},children:(0,n.jsx)(t.p,{children:"\ud83d\udcda Example Apps"})}),(0,n.jsx)("a",{href:"https://github.com/meta-llama/llama-stack",style:{border:"2px solid #666",color:"#666",padding:"0.75rem 1.5rem",borderRadius:"0.5rem",textDecoration:"none",fontWeight:"bold"},children:(0,n.jsx)(t.p,{children:"\u2b50 Star on GitHub"})})]})]})}function m(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}}}]);