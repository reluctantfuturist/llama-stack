"use strict";(self.webpackChunkdocusaurus_template_openapi_docs=self.webpackChunkdocusaurus_template_openapi_docs||[]).push([[1109],{28453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>a});var i=t(96540);const s={},r=i.createContext(s);function l(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),i.createElement(r.Provider,{value:n},e.children)}},45336:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"distributions/ondevice-distro/ios-sdk","title":"iOS SDK","description":"Native iOS development with Llama Stack using Swift SDK for remote and on-device inference","source":"@site/docs/distributions/ondevice-distro/ios-sdk.mdx","sourceDirName":"distributions/ondevice-distro","slug":"/distributions/ondevice-distro/ios-sdk","permalink":"/llama-stack/docs/distributions/ondevice-distro/ios-sdk","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/distributions/ondevice-distro/ios-sdk.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"iOS SDK","description":"Native iOS development with Llama Stack using Swift SDK for remote and on-device inference","sidebar_label":"iOS SDK","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"watsonx","permalink":"/llama-stack/docs/distributions/remote-hosted-distro/watsonx"},"next":{"title":"Android SDK","permalink":"/llama-stack/docs/distributions/ondevice-distro/android-sdk"}}');var s=t(74848),r=t(28453),l=t(64911),a=t(79329);const o={title:"iOS SDK",description:"Native iOS development with Llama Stack using Swift SDK for remote and on-device inference",sidebar_label:"iOS SDK",sidebar_position:1},c="iOS SDK",d={},u=[{value:"Remote Only",id:"remote-only",level:2},{value:"Setup",id:"setup",level:3},{value:"LocalInference",id:"localinference",level:2},{value:"Installation",id:"installation",level:3},{value:"Preparing a Model",id:"preparing-a-model",level:3},{value:"Using LocalInference",id:"using-localinference",level:3},{value:"Troubleshooting",id:"troubleshooting",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Related Resources",id:"related-resources",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"ios-sdk",children:"iOS SDK"})}),"\n",(0,s.jsxs)(n.p,{children:["We offer both remote and on-device use of Llama Stack in Swift via a single SDK ",(0,s.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack-client-swift/",children:"llama-stack-client-swift"})," that contains two components:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"LlamaStackClient"})," for remote inference"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Local Inference"})," for on-device inference"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Seamlessly switching between local, on-device inference and remote hosted inference",src:t(91379).A+"",width:"412",height:"412"})}),"\n",(0,s.jsx)(n.h2,{id:"remote-only",children:"Remote Only"}),"\n",(0,s.jsx)(n.p,{children:"If you don't want to run inference on-device, then you can connect to any hosted Llama Stack distribution with the remote client."}),"\n",(0,s.jsx)(n.h3,{id:"setup",children:"Setup"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Add ",(0,s.jsx)(n.code,{children:"https://github.com/meta-llama/llama-stack-client-swift/"})," as a Package Dependency in Xcode"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Add ",(0,s.jsx)(n.code,{children:"LlamaStackClient"})," as a framework to your app target"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Call an API:"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-swift",children:'import LlamaStackClient\n\nlet agents = RemoteAgents(url: URL(string: "http://localhost:8321")!)\nlet request = Components.Schemas.CreateAgentTurnRequest(\n        agent_id: agentId,\n        messages: [\n          .UserMessage(Components.Schemas.UserMessage(\n            content: .case1("Hello Llama!"),\n            role: .user\n          ))\n        ],\n        session_id: self.agenticSystemSessionId,\n        stream: true\n      )\n\n      for try await chunk in try await agents.createTurn(request: request) {\n        let payload = chunk.event.payload\n      // ...\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Check out ",(0,s.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack-client-swift/tree/main/examples/ios_calendar_assistant",children:"iOSCalendarAssistant"})," for a complete app demo."]}),"\n",(0,s.jsx)(n.h2,{id:"localinference",children:"LocalInference"}),"\n",(0,s.jsxs)(n.p,{children:["LocalInference provides a local inference implementation powered by ",(0,s.jsx)(n.a,{href:"https://github.com/pytorch/executorch/",children:"executorch"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Llama Stack currently supports on-device inference for iOS with Android coming soon. You can run on-device inference on Android today using ",(0,s.jsx)(n.a,{href:"https://github.com/pytorch/executorch/tree/main/examples/demo-apps/android/LlamaDemo",children:"executorch"}),", PyTorch's on-device inference library."]}),"\n",(0,s.jsxs)(n.p,{children:["The APIs ",(0,s.jsx)(n.em,{children:"work the same as remote"})," \u2013 the only difference is you'll instead use the ",(0,s.jsx)(n.code,{children:"LocalAgents"})," / ",(0,s.jsx)(n.code,{children:"LocalInference"})," classes and pass in a ",(0,s.jsx)(n.code,{children:"DispatchQueue"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-swift",children:'private let runnerQueue = DispatchQueue(label: "org.llamastack.stacksummary")\nlet inference = LocalInference(queue: runnerQueue)\nlet agents = LocalAgents(inference: self.inference)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Check out ",(0,s.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack-client-swift/tree/main/examples/ios_calendar_assistant",children:"iOSCalendarAssistantWithLocalInf"})," for a complete app demo."]}),"\n",(0,s.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,s.jsx)(n.admonition,{title:"Development Status",type:"info",children:(0,s.jsxs)(n.p,{children:["We're working on making LocalInference easier to set up. For now, you'll need to import it via ",(0,s.jsx)(n.code,{children:".xcframework"}),"."]})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Clone the executorch submodule in this repo and its dependencies: ",(0,s.jsx)(n.code,{children:"git submodule update --init --recursive"})]}),"\n",(0,s.jsxs)(n.li,{children:["Install ",(0,s.jsx)(n.a,{href:"https://cmake.org/",children:"Cmake"})," for the executorch build"]}),"\n",(0,s.jsxs)(n.li,{children:["Drag ",(0,s.jsx)(n.code,{children:"LocalInference.xcodeproj"})," into your project"]}),"\n",(0,s.jsxs)(n.li,{children:["Add ",(0,s.jsx)(n.code,{children:"LocalInference"})," as a framework in your app target"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"preparing-a-model",children:"Preparing a Model"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Prepare a ",(0,s.jsx)(n.code,{children:".pte"})," file ",(0,s.jsx)(n.a,{href:"https://github.com/pytorch/executorch/blob/main/examples/models/llama/README.md#step-2-prepare-model",children:"following the executorch docs"})]}),"\n",(0,s.jsxs)(n.li,{children:["Bundle the ",(0,s.jsx)(n.code,{children:".pte"})," and ",(0,s.jsx)(n.code,{children:"tokenizer.model"})," file into your app"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"We now support models quantized using SpinQuant and QAT-LoRA which offer a significant performance boost (demo app on iPhone 13 Pro):"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Llama 3.2 1B"}),(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Tokens / Second (total)"}),(0,s.jsx)(n.th,{style:{textAlign:"left"}}),(0,s.jsx)(n.th,{style:{textAlign:"left"},children:"Time-to-First-Token (sec)"}),(0,s.jsx)(n.th,{style:{textAlign:"left"}})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"}}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Haiku"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Paragraph"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Haiku"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"Paragraph"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"BF16"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"2.2"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"2.5"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"2.3"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"1.9"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"QAT+LoRA"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"7.1"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"3.3"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"0.37"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"0.24"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"SpinQuant"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"10.1"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"5.2"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"0.2"}),(0,s.jsx)(n.td,{style:{textAlign:"left"},children:"0.2"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"using-localinference",children:"Using LocalInference"}),"\n",(0,s.jsxs)(l.A,{children:[(0,s.jsxs)(a.default,{value:"init",label:"1. Initialize",children:[(0,s.jsx)(n.p,{children:"Instantiate LocalInference with a DispatchQueue. Optionally, pass it into your agents service:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-swift",children:'init () {\n  runnerQueue = DispatchQueue(label: "org.meta.llamastack")\n  inferenceService = LocalInferenceService(queue: runnerQueue)\n  agentsService = LocalAgentsService(inference: inferenceService)\n}\n'})})]}),(0,s.jsxs)(a.default,{value:"load",label:"2. Load Model",children:[(0,s.jsx)(n.p,{children:"Before making any inference calls, load your model from your bundle:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-swift",children:'let mainBundle = Bundle.main\ninferenceService.loadModel(\n    modelPath: mainBundle.url(forResource: "llama32_1b_spinquant", withExtension: "pte"),\n    tokenizerPath: mainBundle.url(forResource: "tokenizer", withExtension: "model"),\n    completion: {_ in } // use to handle load failures\n)\n'})})]}),(0,s.jsxs)(a.default,{value:"inference",label:"3. Make Inference Calls",children:[(0,s.jsx)(n.p,{children:"Make inference calls (or agents calls) as you normally would with LlamaStack:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-swift",children:'for await chunk in try await agentsService.initAndCreateTurn(\n    messages: [\n    .UserMessage(Components.Schemas.UserMessage(\n        content: .case1("Call functions as needed to handle any actions in the following text:\\n\\n" + text),\n        role: .user))\n    ]\n) {\n'})})]})]}),"\n",(0,s.jsx)(n.h3,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.p,{children:'If you receive errors like "missing package product" or "invalid checksum", try cleaning the build folder and resetting the Swift package cache:'}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"(Opt+Click) Product > Clean Build Folder Immediately"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"rm -rf \\\n  ~/Library/org.swift.swiftpm \\\n  ~/Library/Caches/org.swift.swiftpm \\\n  ~/Library/Caches/com.apple.dt.Xcode \\\n  ~/Library/Developer/Xcode/DerivedData\n"})}),"\n",(0,s.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model Size"}),": Smaller models (1B-3B parameters) work best on mobile devices"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Quantization"}),": Use SpinQuant or QAT-LoRA for optimal performance"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Memory Usage"}),": Monitor app memory usage with larger models"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Battery Life"}),": On-device inference can impact battery performance"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,s.jsx)(n.p,{children:"The iOS SDK is ideal for:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Native iOS applications"})," requiring AI capabilities"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Offline functionality"})," without internet dependency"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Privacy-focused"})," applications processing sensitive data locally"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Real-time inference"})," with low latency requirements"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hybrid applications"})," switching between local and remote inference"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack-client-swift/",children:"llama-stack-client-swift"})})," - Official Swift SDK repository"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack-client-swift/tree/main/examples/ios_calendar_assistant",children:"iOS Calendar Assistant"})})," - Complete example app"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"https://github.com/pytorch/executorch/",children:"executorch"})})," - PyTorch on-device inference library"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"./android-sdk",children:"Android SDK"})})," - Android development guide"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},64911:(e,n,t)=>{t.d(n,{A:()=>m});var i=t(96540),s=t(34164),r=t(65627),l=t(77448),a=t(9136);const o={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=t(74848);function d({className:e,block:n,selectedValue:t,selectValue:i,tabValues:l}){const a=[],{blockElementScrollPositionUntilNextRender:d}=(0,r.a_)(),u=e=>{const n=e.currentTarget,s=a.indexOf(n),r=l[s].value;r!==t&&(d(n),i(r))},h=e=>{let n=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const t=a.indexOf(e.currentTarget)+1;n=a[t]??a[0];break}case"ArrowLeft":{const t=a.indexOf(e.currentTarget)-1;n=a[t]??a[a.length-1];break}}n?.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:l.map(({value:e,label:n,attributes:i})=>(0,c.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{a.push(e)},onKeyDown:h,onClick:u,...i,className:(0,s.A)("tabs__item",o.tabItem,i?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function u({lazy:e,children:n,selectedValue:t}){const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=r.find(e=>e.props.value===t);return e?(0,i.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:r.map((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function h(e){const n=(0,l.u)(e);return(0,c.jsxs)("div",{className:(0,s.A)("tabs-container",o.tabList),children:[(0,c.jsx)(d,{...n,...e}),(0,c.jsx)(u,{...n,...e})]})}function m(e){const n=(0,a.default)();return(0,c.jsx)(h,{...e,children:(0,l.v)(e.children)},String(n))}},77448:(e,n,t)=>{t.d(n,{u:()=>m,v:()=>c});var i=t(96540),s=t(56347),r=t(50372),l=t(30604),a=t(78749),o=t(11861);function c(e){return i.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function d(e){const{values:n,children:t}=e;return(0,i.useMemo)(()=>{const e=n??function(e){return c(e).map(({props:{value:e,label:n,attributes:t,default:i}})=>({value:e,label:n,attributes:t,default:i}))}(t);return function(e){const n=(0,o.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function u({value:e,tabValues:n}){return n.some(n=>n.value===e)}function h({queryString:e=!1,groupId:n}){const t=(0,s.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(r),(0,i.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}function m(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,l=d(e),[o,c]=(0,i.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:l})),[m,f]=h({queryString:t,groupId:s}),[p,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,s]=(0,a.Dv)(n);return[t,(0,i.useCallback)(e=>{n&&s.set(e)},[n,s])]}({groupId:s}),g=(()=>{const e=m??p;return u({value:e,tabValues:l})?e:null})();(0,r.A)(()=>{g&&c(g)},[g]);return{selectedValue:o,selectValue:(0,i.useCallback)(e=>{if(!u({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);c(e),f(e),x(e)},[f,x,l]),tabValues:l}}},79329:(e,n,t)=>{t.r(n),t.d(n,{default:()=>l});t(96540);var i=t(34164);const s={tabItem:"tabItem_Ymn6"};var r=t(74848);function l({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,i.A)(s.tabItem,t),hidden:n,children:e})}},91379:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/remote_or_local-1ddf31143dd6f2bae3487e54ab3a6380.gif"}}]);