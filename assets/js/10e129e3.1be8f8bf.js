"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6421],{4865:(e,r,i)=>{i.d(r,{A:()=>j});var n=i(96540),s=i(34164),l=i(23104),t=i(47751),o=i(92303);const d={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=i(74848);function a(e){var r=e.className,i=e.block,n=e.selectedValue,t=e.selectValue,o=e.tabValues,a=[],h=(0,l.a_)().blockElementScrollPositionUntilNextRender,x=function(e){var r=e.currentTarget,i=a.indexOf(r),s=o[i].value;s!==n&&(h(r),t(s))},j=function(e){var r,i=null;switch(e.key){case"Enter":x(e);break;case"ArrowRight":var n,s=a.indexOf(e.currentTarget)+1;i=null!=(n=a[s])?n:a[0];break;case"ArrowLeft":var l,t=a.indexOf(e.currentTarget)-1;i=null!=(l=a[t])?l:a[a.length-1]}null==(r=i)||r.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":i},r),children:o.map(function(e){var r=e.value,i=e.label,l=e.attributes;return(0,c.jsx)("li",Object.assign({role:"tab",tabIndex:n===r?0:-1,"aria-selected":n===r,ref:function(e){a.push(e)},onKeyDown:j,onClick:x},l,{className:(0,s.A)("tabs__item",d.tabItem,null==l?void 0:l.className,{"tabs__item--active":n===r}),children:null!=i?i:r}),r)})})}function h(e){var r=e.lazy,i=e.children,l=e.selectedValue,t=(Array.isArray(i)?i:[i]).filter(Boolean);if(r){var o=t.find(function(e){return e.props.value===l});return o?(0,n.cloneElement)(o,{className:(0,s.A)("margin-top--md",o.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:t.map(function(e,r){return(0,n.cloneElement)(e,{key:r,hidden:e.props.value!==l})})})}function x(e){var r=(0,t.u)(e);return(0,c.jsxs)("div",{className:(0,s.A)("tabs-container",d.tabList),children:[(0,c.jsx)(a,Object.assign({},r,e)),(0,c.jsx)(h,Object.assign({},r,e))]})}function j(e){var r=(0,o.default)();return(0,c.jsx)(x,Object.assign({},e,{children:(0,t.v)(e.children)}),String(r))}},28727:(e,r,i)=>{i.r(r),i.d(r,{assets:()=>a,contentTitle:()=>c,default:()=>j,frontMatter:()=>d,metadata:()=>n,toc:()=>h});const n=JSON.parse('{"id":"distributions/self-hosted-distro/starter","title":"Starter Distribution","description":"Comprehensive multi-provider distribution for quick prototyping and experimentation","source":"@site/docs/distributions/self-hosted-distro/starter.mdx","sourceDirName":"distributions/self-hosted-distro","slug":"/distributions/self-hosted-distro/starter","permalink":"/docs/distributions/self-hosted-distro/starter","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/distributions/self-hosted-distro/starter.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"Starter Distribution","description":"Comprehensive multi-provider distribution for quick prototyping and experimentation","sidebar_label":"Starter","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Starting Llama Stack Server","permalink":"/docs/distributions/starting-llama-stack-server"},"next":{"title":"Dell","permalink":"/docs/distributions/self-hosted-distro/dell"}}');var s=i(74848),l=i(28453),t=i(4865),o=i(19365);const d={title:"Starter Distribution",description:"Comprehensive multi-provider distribution for quick prototyping and experimentation",sidebar_label:"Starter",sidebar_position:6},c="Starter Distribution",a={},h=[{value:"Provider Composition",id:"provider-composition",level:2},{value:"Inference Providers",id:"inference-providers",level:2},{value:"Hosted Providers",id:"hosted-providers",level:3},{value:"Local/Remote Providers",id:"localremote-providers",level:3},{value:"Vector IO",id:"vector-io",level:2},{value:"Environment Variables",id:"environment-variables",level:2},{value:"Server Configuration",id:"server-configuration",level:3},{value:"API Keys for Hosted Providers",id:"api-keys-for-hosted-providers",level:3},{value:"Local Provider Configuration",id:"local-provider-configuration",level:3},{value:"Model Configuration",id:"model-configuration",level:3},{value:"Vector Database Configuration",id:"vector-database-configuration",level:3},{value:"Tool Configuration",id:"tool-configuration",level:3},{value:"Telemetry Configuration",id:"telemetry-configuration",level:3},{value:"Enabling Providers",id:"enabling-providers",level:2},{value:"Running the Distribution",id:"running-the-distribution",level:2},{value:"Example Usage",id:"example-usage",level:2},{value:"Using OpenAI Models",id:"using-openai-models",level:3},{value:"Using Fireworks Models",id:"using-fireworks-models",level:3},{value:"Using Local Ollama Models",id:"using-local-ollama-models",level:3},{value:"Storage",id:"storage",level:2},{value:"Benefits of the Starter Distribution",id:"benefits-of-the-starter-distribution",level:2},{value:"Related Guides",id:"related-guides",level:2}];function x(e){const r={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(r.header,{children:(0,s.jsx)(r.h1,{id:"starter-distribution",children:"Starter Distribution"})}),"\n",(0,s.jsxs)(r.p,{children:["The ",(0,s.jsx)(r.code,{children:"llamastack/distribution-starter"})," distribution is a comprehensive, multi-provider distribution that includes most of the available inference providers in Llama Stack. It's designed to be a one-stop solution for developers who want to experiment with different AI providers without having to configure each one individually."]}),"\n",(0,s.jsx)(r.h2,{id:"provider-composition",children:"Provider Composition"}),"\n",(0,s.jsx)(r.p,{children:"The starter distribution consists of the following provider configurations:"}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"API"}),(0,s.jsx)(r.th,{children:"Provider(s)"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"agents"}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"inline::meta-reference"})})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"datasetio"}),(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"remote::huggingface"}),", ",(0,s.jsx)(r.code,{children:"inline::localfs"})]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"eval"}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"inline::meta-reference"})})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"files"}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"inline::localfs"})})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"inference"}),(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"remote::openai"}),", ",(0,s.jsx)(r.code,{children:"remote::fireworks"}),", ",(0,s.jsx)(r.code,{children:"remote::together"}),", ",(0,s.jsx)(r.code,{children:"remote::ollama"}),", ",(0,s.jsx)(r.code,{children:"remote::anthropic"}),", ",(0,s.jsx)(r.code,{children:"remote::gemini"}),", ",(0,s.jsx)(r.code,{children:"remote::groq"}),", ",(0,s.jsx)(r.code,{children:"remote::sambanova"}),", ",(0,s.jsx)(r.code,{children:"remote::vllm"}),", ",(0,s.jsx)(r.code,{children:"remote::tgi"}),", ",(0,s.jsx)(r.code,{children:"remote::cerebras"}),", ",(0,s.jsx)(r.code,{children:"remote::llama-openai-compat"}),", ",(0,s.jsx)(r.code,{children:"remote::nvidia"}),", ",(0,s.jsx)(r.code,{children:"remote::hf::serverless"}),", ",(0,s.jsx)(r.code,{children:"remote::hf::endpoint"}),", ",(0,s.jsx)(r.code,{children:"inline::sentence-transformers"})]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"safety"}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"inline::llama-guard"})})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"scoring"}),(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"inline::basic"}),", ",(0,s.jsx)(r.code,{children:"inline::llm-as-judge"}),", ",(0,s.jsx)(r.code,{children:"inline::braintrust"})]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"telemetry"}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"inline::meta-reference"})})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"tool_runtime"}),(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"remote::brave-search"}),", ",(0,s.jsx)(r.code,{children:"remote::tavily-search"}),", ",(0,s.jsx)(r.code,{children:"inline::rag-runtime"}),", ",(0,s.jsx)(r.code,{children:"remote::model-context-protocol"})]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"vector_io"}),(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"inline::faiss"}),", ",(0,s.jsx)(r.code,{children:"inline::sqlite-vec"}),", ",(0,s.jsx)(r.code,{children:"inline::milvus"}),", ",(0,s.jsx)(r.code,{children:"remote::chromadb"}),", ",(0,s.jsx)(r.code,{children:"remote::pgvector"})]})]})]})]}),"\n",(0,s.jsx)(r.h2,{id:"inference-providers",children:"Inference Providers"}),"\n",(0,s.jsx)(r.p,{children:"The starter distribution includes a comprehensive set of inference providers:"}),"\n",(0,s.jsx)(r.h3,{id:"hosted-providers",children:"Hosted Providers"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://openai.com/api/",children:"OpenAI"})}),": GPT-4, GPT-3.5, O1, O3, O4 models and text embeddings (provider ID: ",(0,s.jsx)(r.code,{children:"openai"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://fireworks.ai/",children:"Fireworks"})}),": Llama 3.1, 3.2, 3.3, 4 Scout, 4 Maverick models and embeddings (provider ID: ",(0,s.jsx)(r.code,{children:"fireworks"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://together.ai/",children:"Together"})}),": Llama 3.1, 3.2, 3.3, 4 Scout, 4 Maverick models and embeddings (provider ID: ",(0,s.jsx)(r.code,{children:"together"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://www.anthropic.com/",children:"Anthropic"})}),": Claude 3.5 Sonnet, Claude 3.7 Sonnet, Claude 3.5 Haiku, and Voyage embeddings (provider ID: ",(0,s.jsx)(r.code,{children:"anthropic"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://gemini.google.com/",children:"Gemini"})}),": Gemini 1.5, 2.0, 2.5 models and text embeddings (provider ID: ",(0,s.jsx)(r.code,{children:"gemini"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://groq.com/",children:"Groq"})}),": Fast Llama models (3.1, 3.2, 3.3, 4 Scout, 4 Maverick) (provider ID: ",(0,s.jsx)(r.code,{children:"groq"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://www.sambanova.ai/",children:"SambaNova"})}),": Llama 3.1, 3.2, 3.3, 4 Scout, 4 Maverick models (provider ID: ",(0,s.jsx)(r.code,{children:"sambanova"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://www.cerebras.ai/",children:"Cerebras"})}),": Cerebras AI models (provider ID: ",(0,s.jsx)(r.code,{children:"cerebras"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://www.nvidia.com/",children:"NVIDIA"})}),": NVIDIA NIM (provider ID: ",(0,s.jsx)(r.code,{children:"nvidia"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://huggingface.co/",children:"HuggingFace"})}),": Serverless and endpoint models (provider ID: ",(0,s.jsx)(r.code,{children:"hf::serverless"})," and ",(0,s.jsx)(r.code,{children:"hf::endpoint"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://aws.amazon.com/bedrock/",children:"Bedrock"})}),": AWS Bedrock models (provider ID: ",(0,s.jsx)(r.code,{children:"bedrock"}),")"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"localremote-providers",children:"Local/Remote Providers"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://ollama.ai/",children:"Ollama"})}),": Local Ollama models (provider ID: ",(0,s.jsx)(r.code,{children:"ollama"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://docs.vllm.ai/en/latest/",children:"vLLM"})}),": Local or remote vLLM server (provider ID: ",(0,s.jsx)(r.code,{children:"vllm"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://github.com/huggingface/text-generation-inference",children:"TGI"})}),": Text Generation Inference server (provider ID: ",(0,s.jsx)(r.code,{children:"tgi"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://www.sbert.net/",children:"Sentence Transformers"})}),": Local embedding models (provider ID: ",(0,s.jsx)(r.code,{children:"sentence-transformers"}),")"]}),"\n"]}),"\n",(0,s.jsx)(r.admonition,{type:"info",children:(0,s.jsx)(r.p,{children:"All providers are disabled by default. You need to enable them by setting the appropriate environment variables."})}),"\n",(0,s.jsx)(r.h2,{id:"vector-io",children:"Vector IO"}),"\n",(0,s.jsx)(r.p,{children:"The starter distribution includes a comprehensive set of vector IO providers:"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://github.com/facebookresearch/faiss",children:"FAISS"})}),": Local FAISS vector store - enabled by default (provider ID: ",(0,s.jsx)(r.code,{children:"faiss"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://www.sqlite.org/index.html",children:"SQLite"})}),": Local SQLite vector store - disabled by default (provider ID: ",(0,s.jsx)(r.code,{children:"sqlite-vec"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://www.trychroma.com/",children:"ChromaDB"})}),": Remote ChromaDB vector store - disabled by default (provider ID: ",(0,s.jsx)(r.code,{children:"chromadb"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://github.com/pgvector/pgvector",children:"PGVector"})}),": PostgreSQL vector store - disabled by default (provider ID: ",(0,s.jsx)(r.code,{children:"pgvector"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"https://milvus.io/",children:"Milvus"})}),": Milvus vector store - disabled by default (provider ID: ",(0,s.jsx)(r.code,{children:"milvus"}),")"]}),"\n"]}),"\n",(0,s.jsx)(r.h2,{id:"environment-variables",children:"Environment Variables"}),"\n",(0,s.jsx)(r.h3,{id:"server-configuration",children:"Server Configuration"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"LLAMA_STACK_PORT"}),": Port for the Llama Stack distribution server (default: ",(0,s.jsx)(r.code,{children:"8321"}),")"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"api-keys-for-hosted-providers",children:"API Keys for Hosted Providers"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"OPENAI_API_KEY"}),": OpenAI API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"FIREWORKS_API_KEY"}),": Fireworks API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"TOGETHER_API_KEY"}),": Together API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"ANTHROPIC_API_KEY"}),": Anthropic API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"GEMINI_API_KEY"}),": Google Gemini API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"GROQ_API_KEY"}),": Groq API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"SAMBANOVA_API_KEY"}),": SambaNova API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"CEREBRAS_API_KEY"}),": Cerebras API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"LLAMA_API_KEY"}),": Llama API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"NVIDIA_API_KEY"}),": NVIDIA API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"HF_API_TOKEN"}),": HuggingFace API token"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"local-provider-configuration",children:"Local Provider Configuration"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"OLLAMA_URL"}),": Ollama server URL (default: ",(0,s.jsx)(r.code,{children:"http://localhost:11434"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"VLLM_URL"}),": vLLM server URL (default: ",(0,s.jsx)(r.code,{children:"http://localhost:8000/v1"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"VLLM_MAX_TOKENS"}),": vLLM max tokens (default: ",(0,s.jsx)(r.code,{children:"4096"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"VLLM_API_TOKEN"}),": vLLM API token (default: ",(0,s.jsx)(r.code,{children:"fake"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"VLLM_TLS_VERIFY"}),": vLLM TLS verification (default: ",(0,s.jsx)(r.code,{children:"true"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"TGI_URL"}),": TGI server URL"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"model-configuration",children:"Model Configuration"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"INFERENCE_MODEL"}),": HuggingFace model for serverless inference"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"INFERENCE_ENDPOINT_NAME"}),": HuggingFace endpoint name"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"vector-database-configuration",children:"Vector Database Configuration"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"SQLITE_STORE_DIR"}),": SQLite store directory (default: ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"ENABLE_SQLITE_VEC"}),": Enable SQLite vector provider"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"ENABLE_CHROMADB"}),": Enable ChromaDB provider"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"ENABLE_PGVECTOR"}),": Enable PGVector provider"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"CHROMADB_URL"}),": ChromaDB server URL"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"PGVECTOR_HOST"}),": PGVector host (default: ",(0,s.jsx)(r.code,{children:"localhost"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"PGVECTOR_PORT"}),": PGVector port (default: ",(0,s.jsx)(r.code,{children:"5432"}),")"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"PGVECTOR_DB"}),": PGVector database name"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"PGVECTOR_USER"}),": PGVector username"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"PGVECTOR_PASSWORD"}),": PGVector password"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"tool-configuration",children:"Tool Configuration"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"BRAVE_SEARCH_API_KEY"}),": Brave Search API key"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"TAVILY_SEARCH_API_KEY"}),": Tavily Search API key"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"telemetry-configuration",children:"Telemetry Configuration"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"OTEL_SERVICE_NAME"}),": OpenTelemetry service name"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.code,{children:"TELEMETRY_SINKS"}),": Telemetry sinks (default: ",(0,s.jsx)(r.code,{children:"console,sqlite"}),")"]}),"\n"]}),"\n",(0,s.jsx)(r.h2,{id:"enabling-providers",children:"Enabling Providers"}),"\n",(0,s.jsx)(r.p,{children:"You can enable specific providers by setting appropriate environment variables. For example:"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-bash",children:"# self-hosted\nexport OLLAMA_URL=http://localhost:11434   # enables the Ollama inference provider\nexport VLLM_URL=http://localhost:8000/v1   # enables the vLLM inference provider\nexport TGI_URL=http://localhost:8000/v1   # enables the TGI inference provider\n\n# cloud-hosted requiring API key configuration on the server\nexport CEREBRAS_API_KEY=your_cerebras_api_key   # enables the Cerebras inference provider\nexport NVIDIA_API_KEY=your_nvidia_api_key   # enables the NVIDIA inference provider\n\n# vector providers\nexport MILVUS_URL=http://localhost:19530   # enables the Milvus vector provider\nexport CHROMADB_URL=http://localhost:8000/v1   # enables the ChromaDB vector provider\nexport PGVECTOR_DB=llama_stack_db   # enables the PGVector vector provider\n"})}),"\n",(0,s.jsxs)(r.p,{children:['This distribution comes with a default "llama-guard" shield that can be enabled by setting the ',(0,s.jsx)(r.code,{children:"SAFETY_MODEL"})," environment variable to point to an appropriate Llama Guard model id. Use ",(0,s.jsx)(r.code,{children:"llama-stack-client models list"})," to see the list of available models."]}),"\n",(0,s.jsx)(r.h2,{id:"running-the-distribution",children:"Running the Distribution"}),"\n",(0,s.jsxs)(t.A,{children:[(0,s.jsxs)(o.default,{value:"docker",label:"Via Docker",children:[(0,s.jsx)(r.p,{children:"This method allows you to get started quickly without having to build the distribution code."}),(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-bash",children:"LLAMA_STACK_PORT=8321\ndocker run \\\n  -it \\\n  --pull always \\\n  -p $LLAMA_STACK_PORT:$LLAMA_STACK_PORT \\\n  -e OPENAI_API_KEY=your_openai_key \\\n  -e FIREWORKS_API_KEY=your_fireworks_key \\\n  -e TOGETHER_API_KEY=your_together_key \\\n  llamastack/distribution-starter \\\n  --port $LLAMA_STACK_PORT\n"})})]}),(0,s.jsxs)(o.default,{value:"venv",label:"Via venv",children:[(0,s.jsx)(r.p,{children:"Ensure you have configured the starter distribution using the environment variables explained above."}),(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-bash",children:"uv run --with llama-stack llama stack build --distro starter --image-type venv --run\n"})})]})]}),"\n",(0,s.jsx)(r.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,s.jsx)(r.p,{children:"Once the distribution is running, you can use any of the available models. Here are some examples:"}),"\n",(0,s.jsx)(r.h3,{id:"using-openai-models",children:"Using OpenAI Models"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-bash",children:'llama-stack-client --endpoint http://localhost:8321 \\\ninference chat-completion \\\n--model-id openai/gpt-4o \\\n--message "Hello, how are you?"\n'})}),"\n",(0,s.jsx)(r.h3,{id:"using-fireworks-models",children:"Using Fireworks Models"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-bash",children:'llama-stack-client --endpoint http://localhost:8321 \\\ninference chat-completion \\\n--model-id fireworks/meta-llama/Llama-3.2-3B-Instruct \\\n--message "Write a short story about a robot."\n'})}),"\n",(0,s.jsx)(r.h3,{id:"using-local-ollama-models",children:"Using Local Ollama Models"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-bash",children:'# First, make sure Ollama is running and you have a model\nollama run llama3.2:3b\n\n# Then use it through Llama Stack\nexport OLLAMA_INFERENCE_MODEL=llama3.2:3b\nllama-stack-client --endpoint http://localhost:8321 \\\ninference chat-completion \\\n--model-id ollama/llama3.2:3b \\\n--message "Explain quantum computing in simple terms."\n'})}),"\n",(0,s.jsx)(r.h2,{id:"storage",children:"Storage"}),"\n",(0,s.jsx)(r.p,{children:"The starter distribution uses SQLite for local storage of various components:"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Metadata store"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/registry.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Inference store"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/inference_store.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"FAISS store"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/faiss_store.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"SQLite vector store"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/sqlite_vec.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Files metadata"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/files_metadata.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Agents store"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/agents_store.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Responses store"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/responses_store.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Trace store"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/trace_store.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Evaluation store"}),": ",(0,s.jsx)(r.code,{children:"~/.llama/distributions/starter/meta_reference_eval.db"})]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Dataset I/O stores"}),": Various HuggingFace and local filesystem stores"]}),"\n"]}),"\n",(0,s.jsx)(r.h2,{id:"benefits-of-the-starter-distribution",children:"Benefits of the Starter Distribution"}),"\n",(0,s.jsxs)(r.ol,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Comprehensive Coverage"}),": Includes most popular AI providers in one distribution"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Flexible Configuration"}),": Easy to enable/disable providers based on your needs"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"No Local GPU Required"}),": Most providers are cloud-based, making it accessible to developers without high-end hardware"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Easy Migration"}),": Start with hosted providers and gradually move to local ones as needed"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Production Ready"}),": Includes safety, evaluation, and telemetry components"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Tool Integration"}),": Comes with web search, RAG, and model context protocol tools"]}),"\n"]}),"\n",(0,s.jsx)(r.p,{children:"The starter distribution is ideal for developers who want to experiment with different AI providers, build prototypes quickly, or create applications that can work with multiple AI backends."}),"\n",(0,s.jsx)(r.h2,{id:"related-guides",children:"Related Guides"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"../list-of-distributions",children:"Available Distributions"})})," - Compare with other distributions"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"../configuration",children:"Configuration Reference"})})," - Understanding configuration options"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:(0,s.jsx)(r.a,{href:"../building-distro",children:"Building Custom Distributions"})})," - Create your own distribution"]}),"\n"]})]})}function j(e={}){const{wrapper:r}={...(0,l.R)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(x,{...e})}):x(e)}}}]);