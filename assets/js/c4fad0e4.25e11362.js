"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3406],{4865:(e,n,s)=>{s.d(n,{A:()=>u});var r=s(96540),i=s(34164),t=s(23104),l=s(47751),a=s(92303);const o={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=s(74848);function d(e){var n=e.className,s=e.block,r=e.selectedValue,l=e.selectValue,a=e.tabValues,d=[],h=(0,t.a_)().blockElementScrollPositionUntilNextRender,g=function(e){var n=e.currentTarget,s=d.indexOf(n),i=a[s].value;i!==r&&(h(n),l(i))},u=function(e){var n,s=null;switch(e.key){case"Enter":g(e);break;case"ArrowRight":var r,i=d.indexOf(e.currentTarget)+1;s=null!=(r=d[i])?r:d[0];break;case"ArrowLeft":var t,l=d.indexOf(e.currentTarget)-1;s=null!=(t=d[l])?t:d[d.length-1]}null==(n=s)||n.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":s},n),children:a.map(function(e){var n=e.value,s=e.label,t=e.attributes;return(0,c.jsx)("li",Object.assign({role:"tab",tabIndex:r===n?0:-1,"aria-selected":r===n,ref:function(e){d.push(e)},onKeyDown:u,onClick:g},t,{className:(0,i.A)("tabs__item",o.tabItem,null==t?void 0:t.className,{"tabs__item--active":r===n}),children:null!=s?s:n}),n)})})}function h(e){var n=e.lazy,s=e.children,t=e.selectedValue,l=(Array.isArray(s)?s:[s]).filter(Boolean);if(n){var a=l.find(function(e){return e.props.value===t});return a?(0,r.cloneElement)(a,{className:(0,i.A)("margin-top--md",a.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:l.map(function(e,n){return(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==t})})})}function g(e){var n=(0,l.u)(e);return(0,c.jsxs)("div",{className:(0,i.A)("tabs-container",o.tabList),children:[(0,c.jsx)(d,Object.assign({},n,e)),(0,c.jsx)(h,Object.assign({},n,e))]})}function u(e){var n=(0,a.default)();return(0,c.jsx)(g,Object.assign({},e,{children:(0,l.v)(e.children)}),String(n))}},36710:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>o,metadata:()=>r,toc:()=>h});const r=JSON.parse('{"id":"contributing/testing-record-replay","title":"Record-Replay Testing System","description":"Understanding how Llama Stack captures and replays API interactions for testing","source":"@site/docs/contributing/testing-record-replay.mdx","sourceDirName":"contributing","slug":"/contributing/testing-record-replay","permalink":"/docs/contributing/testing-record-replay","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/contributing/testing-record-replay.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Record-Replay Testing System","description":"Understanding how Llama Stack captures and replays API interactions for testing","sidebar_label":"Testing Record-Replay","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"New Vector Database","permalink":"/docs/contributing/new-vector-database"},"next":{"title":"References","permalink":"/docs/references/"}}');var i=s(74848),t=s(28453),l=s(4865),a=s(19365);const o={title:"Record-Replay Testing System",description:"Understanding how Llama Stack captures and replays API interactions for testing",sidebar_label:"Testing Record-Replay",sidebar_position:4},c=void 0,d={},h=[{value:"Overview",id:"overview",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Request Hashing",id:"request-hashing",level:3},{value:"Client Interception",id:"client-interception",level:3},{value:"Storage Architecture",id:"storage-architecture",level:3},{value:"Recording Modes",id:"recording-modes",level:2},{value:"Streaming Support",id:"streaming-support",level:2},{value:"The Challenge",id:"the-challenge",level:3},{value:"The Solution",id:"the-solution",level:3},{value:"Serialization",id:"serialization",level:2},{value:"Usage in Testing",id:"usage-in-testing",level:2},{value:"Environment Variables",id:"environment-variables",level:3},{value:"Recording New Tests",id:"recording-new-tests",level:3},{value:"Debugging Recordings",id:"debugging-recordings",level:2},{value:"Inspecting Storage",id:"inspecting-storage",level:3},{value:"Common Issues",id:"common-issues",level:3},{value:"Design Decisions",id:"design-decisions",level:2},{value:"Why Not Mocks?",id:"why-not-mocks",level:3},{value:"Why Precise Hashing?",id:"why-precise-hashing",level:3},{value:"Why JSON + SQLite?",id:"why-json--sqlite",level:3},{value:"Advanced Usage",id:"advanced-usage",level:2},{value:"Custom Recording Contexts",id:"custom-recording-contexts",level:3},{value:"Conditional Recording",id:"conditional-recording",level:3},{value:"Recording Validation",id:"recording-validation",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"\ud83c\udfaf <strong>Recording Strategy</strong>",id:"-recording-strategy",level:3},{value:"\ud83d\udd27 <strong>Development Workflow</strong>",id:"-development-workflow",level:3},{value:"\ud83d\udea8 <strong>Debugging Tips</strong>",id:"-debugging-tips",level:3},{value:"\ud83d\udcca <strong>Maintenance</strong>",id:"-maintenance",level:3},{value:"Related Resources",id:"related-resources",level:2}];function g(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"Understanding how Llama Stack captures and replays API interactions for reliable, cost-effective testing."}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsxs)(n.p,{children:["The record-replay system solves a fundamental challenge in AI testing: ",(0,i.jsx)(n.strong,{children:"How do you test against expensive, non-deterministic APIs without breaking the bank or dealing with flaky tests?"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"The solution:"})," Intercept API calls, store real responses, and replay them later. This gives you real API behavior without the cost or variability."]}),"\n",(0,i.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,i.jsx)(n.h3,{id:"request-hashing",children:"Request Hashing"}),"\n",(0,i.jsx)(n.p,{children:"Every API request gets converted to a deterministic hash for lookup:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def normalize_request(method: str, url: str, headers: dict, body: dict) -> str:\n    normalized = {\n        "method": method.upper(),\n        "endpoint": urlparse(url).path,  # Just the path, not full URL\n        "body": body,  # Request parameters\n    }\n    return hashlib.sha256(json.dumps(normalized, sort_keys=True).encode()).hexdigest()\n'})}),"\n",(0,i.jsxs)(n.admonition,{title:"Precise Hashing",type:"warning",children:[(0,i.jsx)(n.p,{children:"The hashing is intentionally precise. Different whitespace, float precision, or parameter order produces different hashes. This prevents subtle bugs from false cache hits."}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# These produce DIFFERENT hashes:\n{"content": "Hello world"}\n{"content": "Hello   world\\n"}\n{"temperature": 0.7}\n{"temperature": 0.7000001}\n'})})]}),"\n",(0,i.jsx)(n.h3,{id:"client-interception",children:"Client Interception"}),"\n",(0,i.jsx)(n.p,{children:"The system patches OpenAI and Ollama client methods to intercept calls before they leave your application. This happens transparently - your test code doesn't change."}),"\n",(0,i.jsx)(n.h3,{id:"storage-architecture",children:"Storage Architecture"}),"\n",(0,i.jsx)(n.p,{children:"Recordings are stored as JSON files in the recording directory, looked up by their request hash:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"recordings/\n\u2514\u2500\u2500 responses/\n    \u251c\u2500\u2500 abc123def456.json  # Individual response files\n    \u2514\u2500\u2500 def789ghi012.json\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"JSON files"})," store complete request/response pairs in human-readable format for debugging."]}),"\n",(0,i.jsx)(n.h2,{id:"recording-modes",children:"Recording Modes"}),"\n",(0,i.jsx)(n.p,{children:"The system supports three distinct modes for different testing scenarios:"}),"\n",(0,i.jsxs)(l.A,{children:[(0,i.jsxs)(a.default,{value:"live",label:"LIVE Mode",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Direct API calls"})," with no recording or replay:"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"with inference_recording(mode=InferenceMode.LIVE):\n    response = await client.chat.completions.create(...)\n"})}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Use for:"})}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Initial development and debugging"}),"\n",(0,i.jsx)(n.li,{children:"Testing against real APIs"}),"\n",(0,i.jsx)(n.li,{children:"Validating new functionality"}),"\n"]})]}),(0,i.jsxs)(a.default,{value:"record",label:"RECORD Mode",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Captures API interactions"})," while passing through real responses:"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'with inference_recording(mode=InferenceMode.RECORD, storage_dir="./recordings"):\n    response = await client.chat.completions.create(...)\n    # Real API call made, response captured AND returned\n'})}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"The recording process:"})}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Request intercepted and hashed"}),"\n",(0,i.jsx)(n.li,{children:"Real API call executed"}),"\n",(0,i.jsx)(n.li,{children:"Response captured and serialized"}),"\n",(0,i.jsx)(n.li,{children:"Recording stored to disk"}),"\n",(0,i.jsx)(n.li,{children:"Original response returned to caller"}),"\n"]})]}),(0,i.jsxs)(a.default,{value:"replay",label:"REPLAY Mode",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Returns stored responses"})," instead of making API calls:"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'with inference_recording(mode=InferenceMode.REPLAY, storage_dir="./recordings"):\n    response = await client.chat.completions.create(...)\n    # No API call made, cached response returned instantly\n'})}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"The replay process:"})}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Request intercepted and hashed"}),"\n",(0,i.jsx)(n.li,{children:"Hash looked up in SQLite index"}),"\n",(0,i.jsx)(n.li,{children:"Response loaded from JSON file"}),"\n",(0,i.jsx)(n.li,{children:"Response deserialized and returned"}),"\n",(0,i.jsx)(n.li,{children:"Error if no recording found"}),"\n"]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"streaming-support",children:"Streaming Support"}),"\n",(0,i.jsx)(n.p,{children:"Streaming APIs present a unique challenge: how do you capture an async generator?"}),"\n",(0,i.jsx)(n.h3,{id:"the-challenge",children:"The Challenge"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# How do you record this?\nasync for chunk in client.chat.completions.create(stream=True):\n    process(chunk)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"the-solution",children:"The Solution"}),"\n",(0,i.jsx)(n.p,{children:"The system captures all chunks immediately before yielding any:"}),"\n",(0,i.jsxs)(l.A,{children:[(0,i.jsx)(a.default,{value:"capture",label:"Stream Capture",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'async def handle_streaming_record(response):\n    # Capture complete stream first\n    chunks = []\n    async for chunk in response:\n        chunks.append(chunk)\n\n    # Store complete recording\n    storage.store_recording(\n        request_hash,\n        request_data,\n        {"body": chunks, "is_streaming": True}\n    )\n\n    # Return generator that replays captured chunks\n    async def replay_stream():\n        for chunk in chunks:\n            yield chunk\n\n    return replay_stream()\n'})})}),(0,i.jsxs)(a.default,{value:"benefits",label:"Benefits",children:[(0,i.jsx)(n.p,{children:"This approach ensures:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Complete capture"})," - The entire stream is saved atomically"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Interface preservation"})," - The returned object behaves like the original API"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deterministic replay"})," - Same chunks in the same order every time"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No API changes"})," - Your streaming code works unchanged"]}),"\n"]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"serialization",children:"Serialization"}),"\n",(0,i.jsx)(n.p,{children:"API responses contain complex Pydantic objects that need careful serialization:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def _serialize_response(response):\n    if hasattr(response, "model_dump"):\n        # Preserve type information for proper deserialization\n        return {\n            "__type__": f"{response.__class__.__module__}.{response.__class__.__qualname__}",\n            "__data__": response.model_dump(mode="json"),\n        }\n    return response\n'})}),"\n",(0,i.jsxs)(n.p,{children:["This preserves ",(0,i.jsx)(n.strong,{children:"type safety"})," - when replayed, you get the same Pydantic objects with all their validation and methods."]}),"\n",(0,i.jsx)(n.h2,{id:"usage-in-testing",children:"Usage in Testing"}),"\n",(0,i.jsx)(n.h3,{id:"environment-variables",children:"Environment Variables"}),"\n",(0,i.jsx)(n.p,{children:"Control recording behavior globally:"}),"\n",(0,i.jsxs)(l.A,{children:[(0,i.jsx)(a.default,{value:"env-vars",label:"Environment Variables",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Set recording mode (default: replay)\nexport LLAMA_STACK_TEST_INFERENCE_MODE=replay\n\n# Set recording directory (default: tests/integration/recordings)\nexport LLAMA_STACK_TEST_RECORDING_DIR=/path/to/recordings\n\n# Run tests\npytest tests/integration/\n"})})}),(0,i.jsxs)(a.default,{value:"pytest",label:"Pytest Integration",children:[(0,i.jsxs)(n.p,{children:["The system integrates automatically based on environment variables, requiring ",(0,i.jsx)(n.strong,{children:"no changes"})," to test code."]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Your test code remains unchanged\nasync def test_chat_completion():\n    response = await client.chat.completions.create(\n        model="gpt-3.5-turbo",\n        messages=[{"role": "user", "content": "Hello"}]\n    )\n    assert response.choices[0].message.content\n'})})]})]}),"\n",(0,i.jsx)(n.h3,{id:"recording-new-tests",children:"Recording New Tests"}),"\n",(0,i.jsxs)(l.A,{children:[(0,i.jsx)(a.default,{value:"local-record",label:"Local Recording",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Record new interactions locally\nLLAMA_STACK_TEST_INFERENCE_MODE=record pytest test_new_feature.py\n\n# Record specific test\nLLAMA_STACK_TEST_INFERENCE_MODE=record pytest test_file.py::test_function\n"})})}),(0,i.jsxs)(a.default,{value:"remote-record",label:"Remote Recording",children:[(0,i.jsx)(n.p,{children:"Use the automated GitHub workflow for easier recording:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Record tests for specific subdirectories\n./scripts/github/schedule-record-workflow.sh --test-subdirs "agents,inference"\n\n# Record with specific provider\n./scripts/github/schedule-record-workflow.sh --test-subdirs "agents" --test-provider vllm\n'})})]})]}),"\n",(0,i.jsx)(n.h2,{id:"debugging-recordings",children:"Debugging Recordings"}),"\n",(0,i.jsx)(n.h3,{id:"inspecting-storage",children:"Inspecting Storage"}),"\n",(0,i.jsxs)(l.A,{children:[(0,i.jsx)(a.default,{value:"sqlite",label:"SQLite Queries",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# See what\'s recorded\nsqlite3 recordings/index.sqlite "SELECT endpoint, model, timestamp FROM recordings LIMIT 10;"\n\n# Find recordings by endpoint\nsqlite3 recordings/index.sqlite "SELECT * FROM recordings WHERE endpoint=\'/v1/chat/completions\';"\n\n# Check for specific model\nsqlite3 recordings/index.sqlite "SELECT * FROM recordings WHERE model=\'gpt-3.5-turbo\';"\n'})})}),(0,i.jsx)(a.default,{value:"json",label:"JSON Inspection",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# View specific response\ncat recordings/responses/abc123def456.json | jq '.response.body'\n\n# Compare request details\ncat recordings/responses/abc123.json | jq '.request'\n\n# Pretty print entire recording\ncat recordings/responses/abc123.json | jq '.'\n"})})})]}),"\n",(0,i.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,i.jsxs)(l.A,{children:[(0,i.jsxs)(a.default,{value:"hash-mismatch",label:"Hash Mismatches",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem:"})," Request parameters changed slightly between record and replay"]}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solution:"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Compare request details\ncat recordings/responses/abc123.json | jq '.request'\n\n# Re-record with updated parameters\nrm recordings/responses/failing_hash.json\nLLAMA_STACK_TEST_INFERENCE_MODE=record pytest test_failing.py\n"})})]}),(0,i.jsxs)(a.default,{value:"serialization",label:"Serialization Errors",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem:"})," Response types changed between versions"]}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solution:"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Re-record with updated types\nrm recordings/responses/failing_hash.json\nLLAMA_STACK_TEST_INFERENCE_MODE=record pytest test_failing.py\n"})})]}),(0,i.jsxs)(a.default,{value:"missing",label:"Missing Recordings",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem:"})," New test or changed parameters"]}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solution:"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Record the missing interaction\nLLAMA_STACK_TEST_INFERENCE_MODE=record pytest test_new.py\n"})})]})]}),"\n",(0,i.jsx)(n.h2,{id:"design-decisions",children:"Design Decisions"}),"\n",(0,i.jsx)(n.h3,{id:"why-not-mocks",children:"Why Not Mocks?"}),"\n",(0,i.jsx)(n.p,{children:"Traditional mocking breaks down with AI APIs because:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Complex structures"})," - Response structures are complex and evolve frequently"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Streaming behavior"})," - Hard to mock streaming responses correctly"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Edge cases"})," - Real API edge cases get missed in mocks"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Maintenance burden"})," - Mocks become brittle and hard to maintain"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"why-precise-hashing",children:"Why Precise Hashing?"}),"\n",(0,i.jsxs)(n.p,{children:["Loose hashing (normalizing whitespace, rounding floats) seems convenient but ",(0,i.jsx)(n.strong,{children:"hides bugs"}),". If a test changes slightly, you want to know about it rather than accidentally getting the wrong cached response."]}),"\n",(0,i.jsx)(n.h3,{id:"why-json--sqlite",children:"Why JSON + SQLite?"}),"\n",(0,i.jsx)(n.p,{children:"The hybrid storage approach provides the best of both worlds:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"JSON"})," - Human readable, diff-friendly, easy to inspect and modify"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"SQLite"})," - Fast indexed lookups without loading response bodies"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Combined"})," - Optimal for both performance and debugging"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"advanced-usage",children:"Advanced Usage"}),"\n",(0,i.jsx)(n.h3,{id:"custom-recording-contexts",children:"Custom Recording Contexts"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Record specific API calls only\nwith inference_recording(\n    mode=InferenceMode.RECORD,\n    storage_dir="./custom_recordings",\n    filter_endpoints=["/v1/chat/completions"]\n):\n    # Only chat completions will be recorded\n    response = await client.chat.completions.create(...)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"conditional-recording",children:"Conditional Recording"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Record only if not exists\nmode = InferenceMode.REPLAY\nif not recording_exists(request_hash):\n    mode = InferenceMode.RECORD\n\nwith inference_recording(mode=mode):\n    response = await client.chat.completions.create(...)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"recording-validation",children:"Recording Validation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Validate recordings during CI\ndef validate_recordings():\n    for recording_file in glob("recordings/responses/*.json"):\n        with open(recording_file) as f:\n            data = json.load(f)\n            assert "request" in data\n            assert "response" in data\n            # Additional validation...\n'})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.h3,{id:"-recording-strategy",children:["\ud83c\udfaf ",(0,i.jsx)(n.strong,{children:"Recording Strategy"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Record comprehensive test scenarios once"}),"\n",(0,i.jsx)(n.li,{children:"Use replay mode for regular development"}),"\n",(0,i.jsx)(n.li,{children:"Re-record when API contracts change"}),"\n",(0,i.jsx)(n.li,{children:"Keep recordings in version control"}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-development-workflow",children:["\ud83d\udd27 ",(0,i.jsx)(n.strong,{children:"Development Workflow"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Start with LIVE mode for new features"}),"\n",(0,i.jsx)(n.li,{children:"Switch to RECORD when tests are stable"}),"\n",(0,i.jsx)(n.li,{children:"Use REPLAY for fast iteration"}),"\n",(0,i.jsx)(n.li,{children:"Re-record when responses change"}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-debugging-tips",children:["\ud83d\udea8 ",(0,i.jsx)(n.strong,{children:"Debugging Tips"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Inspect JSON files for response details"}),"\n",(0,i.jsx)(n.li,{children:"Use SQLite queries to find specific recordings"}),"\n",(0,i.jsx)(n.li,{children:"Compare request hashes when tests fail"}),"\n",(0,i.jsx)(n.li,{children:"Clear recordings to force re-recording"}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-maintenance",children:["\ud83d\udcca ",(0,i.jsx)(n.strong,{children:"Maintenance"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Regularly review and clean old recordings"}),"\n",(0,i.jsx)(n.li,{children:"Update recordings when API versions change"}),"\n",(0,i.jsx)(n.li,{children:"Document which recordings are critical"}),"\n",(0,i.jsx)(n.li,{children:"Monitor recording file sizes"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./index",children:"Contributing Overview"})})," - General contribution guidelines"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/testing",children:"Testing Guide"})})," - Complete testing documentation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack/tree/main/tests/integration",children:"Integration Tests"})})," - Example test implementations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack/tree/main/.github/workflows",children:"GitHub Workflows"})})," - Automated recording workflows"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(g,{...e})}):g(e)}}}]);