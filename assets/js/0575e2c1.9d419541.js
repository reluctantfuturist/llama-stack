"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9347],{53416:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>g,contentTitle:()=>h,default:()=>w,frontMatter:()=>y,metadata:()=>o,toc:()=>b});const o=JSON.parse('{"id":"api/supervised-fine-tune","title":"Run supervised fine-tuning of a model.","description":"Run supervised fine-tuning of a model.","source":"@site/docs/api/supervised-fine-tune.api.mdx","sourceDirName":"api","slug":"/api/supervised-fine-tune","permalink":"/docs/api/supervised-fine-tune","draft":false,"unlisted":false,"editUrl":null,"tags":[],"version":"current","frontMatter":{"id":"supervised-fine-tune","title":"Run supervised fine-tuning of a model.","description":"Run supervised fine-tuning of a model.","sidebar_label":"Run supervised fine-tuning of a model.","hide_title":true,"hide_table_of_contents":true,"api":"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","sidebar_class_name":"post api-method","info_path":"docs/api/llama-stack-specification","custom_edit_url":null},"sidebar":"apiSidebar","previous":{"title":"Run preference optimization of a model.","permalink":"/docs/api/preference-optimize"},"next":{"title":"Protocol for prompt management operations.","permalink":"/docs/api/prompts"}}');var r=i(74848),n=i(28453),a=i(57742),s=i.n(a),p=i(78178),d=i.n(p),c=i(19624),l=i.n(c),u=i(96226),f=i.n(u),m=(i(77675),i(19365),i(51107));const y={id:"supervised-fine-tune",title:"Run supervised fine-tuning of a model.",description:"Run supervised fine-tuning of a model.",sidebar_label:"Run supervised fine-tuning of a model.",hide_title:!0,hide_table_of_contents:!0,api:"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",sidebar_class_name:"post api-method",info_path:"docs/api/llama-stack-specification",custom_edit_url:null},h=void 0,g={},b=[];function v(e){const t={p:"p",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(m.default,{as:"h1",className:"openapi__heading",children:"Run supervised fine-tuning of a model."}),"\n",(0,r.jsx)(s(),{method:"post",path:"/v1/post-training/supervised-fine-tune",context:"endpoint"}),"\n",(0,r.jsx)(t.p,{children:"Run supervised fine-tuning of a model."}),"\n",(0,r.jsx)(m.default,{id:"request",as:"h2",className:"openapi-tabs__heading",children:"Request"}),"\n",(0,r.jsx)(d(),{parameters:[]}),"\n",(0,r.jsx)(l(),{title:"Body",body:{content:{"application/json":{schema:{type:"object",properties:{job_uuid:{type:"string",description:"The UUID of the job to create."},training_config:{description:"The training configuration.",type:"object",properties:{n_epochs:{type:"integer",description:"Number of training epochs to run"},max_steps_per_epoch:{type:"integer",default:1,description:"Maximum number of steps to run per epoch"},gradient_accumulation_steps:{type:"integer",default:1,description:"Number of steps to accumulate gradients before updating"},max_validation_steps:{type:"integer",default:1,description:"(Optional) Maximum number of validation steps per epoch"},data_config:{description:"(Optional) Configuration for data loading and formatting",type:"object",properties:{dataset_id:{type:"string",description:"Unique identifier for the training dataset"},batch_size:{type:"integer",description:"Number of samples per training batch"},shuffle:{type:"boolean",description:"Whether to shuffle the dataset during training"},data_format:{description:"Format of the dataset (instruct or dialog)",type:"string",enum:["instruct","dialog"],title:"DatasetFormat"},validation_dataset_id:{type:"string",description:"(Optional) Unique identifier for the validation dataset"},packed:{type:"boolean",default:!1,description:"(Optional) Whether to pack multiple samples into a single sequence for efficiency"},train_on_input:{type:"boolean",default:!1,description:"(Optional) Whether to compute loss on input tokens as well as output tokens"}},additionalProperties:!1,required:["dataset_id","batch_size","shuffle","data_format"],title:"DataConfig"},optimizer_config:{description:"(Optional) Configuration for the optimization algorithm",type:"object",properties:{optimizer_type:{description:"Type of optimizer to use (adam, adamw, or sgd)",type:"string",enum:["adam","adamw","sgd"],title:"OptimizerType"},lr:{type:"number",description:"Learning rate for the optimizer"},weight_decay:{type:"number",description:"Weight decay coefficient for regularization"},num_warmup_steps:{type:"integer",description:"Number of steps for learning rate warmup"}},additionalProperties:!1,required:["optimizer_type","lr","weight_decay","num_warmup_steps"],title:"OptimizerConfig"},efficiency_config:{description:"(Optional) Configuration for memory and compute optimizations",type:"object",properties:{enable_activation_checkpointing:{type:"boolean",default:!1,description:"(Optional) Whether to use activation checkpointing to reduce memory usage"},enable_activation_offloading:{type:"boolean",default:!1,description:"(Optional) Whether to offload activations to CPU to save GPU memory"},memory_efficient_fsdp_wrap:{type:"boolean",default:!1,description:"(Optional) Whether to use memory-efficient FSDP wrapping"},fsdp_cpu_offload:{type:"boolean",default:!1,description:"(Optional) Whether to offload FSDP parameters to CPU"}},additionalProperties:!1,title:"EfficiencyConfig"},dtype:{type:"string",default:"bf16",description:"(Optional) Data type for model parameters (bf16, fp16, fp32)"}},additionalProperties:!1,required:["n_epochs","max_steps_per_epoch","gradient_accumulation_steps"],title:"TrainingConfig"},hyperparam_search_config:{type:"object",additionalProperties:{oneOf:[{type:"null"},{type:"boolean"},{type:"number"},{type:"string"},{type:"array"},{type:"object"}]},description:"The hyperparam search configuration."},logger_config:{type:"object",additionalProperties:{oneOf:[{type:"null"},{type:"boolean"},{type:"number"},{type:"string"},{type:"array"},{type:"object"}]},description:"The logger configuration."},model:{type:"string",description:"The model to fine-tune."},checkpoint_dir:{type:"string",description:"The directory to save checkpoint(s) to."},algorithm_config:{description:"The algorithm configuration.",oneOf:[{type:"object",properties:{type:{type:"string",const:"LoRA",default:"LoRA",description:'Algorithm type identifier, always "LoRA"'},lora_attn_modules:{type:"array",items:{type:"string"},description:"List of attention module names to apply LoRA to"},apply_lora_to_mlp:{type:"boolean",description:"Whether to apply LoRA to MLP layers"},apply_lora_to_output:{type:"boolean",description:"Whether to apply LoRA to output projection layers"},rank:{type:"integer",description:"Rank of the LoRA adaptation (lower rank = fewer parameters)"},alpha:{type:"integer",description:"LoRA scaling parameter that controls adaptation strength"},use_dora:{type:"boolean",default:!1,description:"(Optional) Whether to use DoRA (Weight-Decomposed Low-Rank Adaptation)"},quantize_base:{type:"boolean",default:!1,description:"(Optional) Whether to quantize the base model weights"}},additionalProperties:!1,required:["type","lora_attn_modules","apply_lora_to_mlp","apply_lora_to_output","rank","alpha"],title:"LoraFinetuningConfig",description:"Configuration for Low-Rank Adaptation (LoRA) fine-tuning."},{type:"object",properties:{type:{type:"string",const:"QAT",default:"QAT",description:'Algorithm type identifier, always "QAT"'},quantizer_name:{type:"string",description:"Name of the quantization algorithm to use"},group_size:{type:"integer",description:"Size of groups for grouped quantization"}},additionalProperties:!1,required:["type","quantizer_name","group_size"],title:"QATFinetuningConfig",description:"Configuration for Quantization-Aware Training (QAT) fine-tuning."}],discriminator:{propertyName:"type",mapping:{LoRA:{type:"object",properties:{type:{type:"string",const:"LoRA",default:"LoRA",description:'Algorithm type identifier, always "LoRA"'},lora_attn_modules:{type:"array",items:{type:"string"},description:"List of attention module names to apply LoRA to"},apply_lora_to_mlp:{type:"boolean",description:"Whether to apply LoRA to MLP layers"},apply_lora_to_output:{type:"boolean",description:"Whether to apply LoRA to output projection layers"},rank:{type:"integer",description:"Rank of the LoRA adaptation (lower rank = fewer parameters)"},alpha:{type:"integer",description:"LoRA scaling parameter that controls adaptation strength"},use_dora:{type:"boolean",default:!1,description:"(Optional) Whether to use DoRA (Weight-Decomposed Low-Rank Adaptation)"},quantize_base:{type:"boolean",default:!1,description:"(Optional) Whether to quantize the base model weights"}},additionalProperties:!1,required:["type","lora_attn_modules","apply_lora_to_mlp","apply_lora_to_output","rank","alpha"],title:"LoraFinetuningConfig",description:"Configuration for Low-Rank Adaptation (LoRA) fine-tuning."},QAT:{type:"object",properties:{type:{type:"string",const:"QAT",default:"QAT",description:'Algorithm type identifier, always "QAT"'},quantizer_name:{type:"string",description:"Name of the quantization algorithm to use"},group_size:{type:"integer",description:"Size of groups for grouped quantization"}},additionalProperties:!1,required:["type","quantizer_name","group_size"],title:"QATFinetuningConfig",description:"Configuration for Quantization-Aware Training (QAT) fine-tuning."}}},title:"AlgorithmConfig"}},additionalProperties:!1,required:["job_uuid","training_config","hyperparam_search_config","logger_config"],title:"SupervisedFineTuneRequest"}}},required:!0}}),"\n",(0,r.jsx)(f(),{id:void 0,label:void 0,responses:{200:{description:"A PostTrainingJob.",content:{"application/json":{schema:{type:"object",properties:{job_uuid:{type:"string"}},additionalProperties:!1,required:["job_uuid"],title:"PostTrainingJob"}}}},400:{description:"The request was invalid or malformed",content:{"application/json":{schema:{type:"object",properties:{status:{type:"integer",description:"HTTP status code"},title:{type:"string",description:"Error title, a short summary of the error which is invariant for an error type"},detail:{type:"string",description:"Error detail, a longer human-readable description of the error"},instance:{type:"string",description:"(Optional) A URL which can be used to retrieve more information about the specific occurrence of the error"}},additionalProperties:!1,required:["status","title","detail"],title:"Error",description:"Error response from the API. Roughly follows RFC 7807."},example:{status:400,title:"Bad Request",detail:"The request was invalid or malformed"}}}},429:{description:"The client has sent too many requests in a given amount of time",content:{"application/json":{schema:{type:"object",properties:{status:{type:"integer",description:"HTTP status code"},title:{type:"string",description:"Error title, a short summary of the error which is invariant for an error type"},detail:{type:"string",description:"Error detail, a longer human-readable description of the error"},instance:{type:"string",description:"(Optional) A URL which can be used to retrieve more information about the specific occurrence of the error"}},additionalProperties:!1,required:["status","title","detail"],title:"Error",description:"Error response from the API. Roughly follows RFC 7807."},example:{status:429,title:"Too Many Requests",detail:"You have exceeded the rate limit. Please try again later."}}}},500:{description:"The server encountered an unexpected error",content:{"application/json":{schema:{type:"object",properties:{status:{type:"integer",description:"HTTP status code"},title:{type:"string",description:"Error title, a short summary of the error which is invariant for an error type"},detail:{type:"string",description:"Error detail, a longer human-readable description of the error"},instance:{type:"string",description:"(Optional) A URL which can be used to retrieve more information about the specific occurrence of the error"}},additionalProperties:!1,required:["status","title","detail"],title:"Error",description:"Error response from the API. Roughly follows RFC 7807."},example:{status:500,title:"Internal Server Error",detail:"An unexpected error occurred. Our team has been notified."}}}},default:{description:"An unexpected error occurred",content:{"application/json":{schema:{type:"object",properties:{status:{type:"integer",description:"HTTP status code"},title:{type:"string",description:"Error title, a short summary of the error which is invariant for an error type"},detail:{type:"string",description:"Error detail, a longer human-readable description of the error"},instance:{type:"string",description:"(Optional) A URL which can be used to retrieve more information about the specific occurrence of the error"}},additionalProperties:!1,required:["status","title","detail"],title:"Error",description:"Error response from the API. Roughly follows RFC 7807."},example:{status:0,title:"Error",detail:"An unexpected error occurred"}}}}}})]})}function w(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(v,{...e})}):v(e)}}}]);