"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3782],{4865:(e,n,i)=>{i.d(n,{A:()=>u});var s=i(96540),r=i(34164),t=i(23104),l=i(47751),o=i(92303);const d={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var a=i(74848);function c(e){var n=e.className,i=e.block,s=e.selectedValue,l=e.selectValue,o=e.tabValues,c=[],h=(0,t.a_)().blockElementScrollPositionUntilNextRender,p=function(e){var n=e.currentTarget,i=c.indexOf(n),r=o[i].value;r!==s&&(h(n),l(r))},u=function(e){var n,i=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":var s,r=c.indexOf(e.currentTarget)+1;i=null!=(s=c[r])?s:c[0];break;case"ArrowLeft":var t,l=c.indexOf(e.currentTarget)-1;i=null!=(t=c[l])?t:c[c.length-1]}null==(n=i)||n.focus()};return(0,a.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":i},n),children:o.map(function(e){var n=e.value,i=e.label,t=e.attributes;return(0,a.jsx)("li",Object.assign({role:"tab",tabIndex:s===n?0:-1,"aria-selected":s===n,ref:function(e){c.push(e)},onKeyDown:u,onClick:p},t,{className:(0,r.A)("tabs__item",d.tabItem,null==t?void 0:t.className,{"tabs__item--active":s===n}),children:null!=i?i:n}),n)})})}function h(e){var n=e.lazy,i=e.children,t=e.selectedValue,l=(Array.isArray(i)?i:[i]).filter(Boolean);if(n){var o=l.find(function(e){return e.props.value===t});return o?(0,s.cloneElement)(o,{className:(0,r.A)("margin-top--md",o.props.className)}):null}return(0,a.jsx)("div",{className:"margin-top--md",children:l.map(function(e,n){return(0,s.cloneElement)(e,{key:n,hidden:e.props.value!==t})})})}function p(e){var n=(0,l.u)(e);return(0,a.jsxs)("div",{className:(0,r.A)("tabs-container",d.tabList),children:[(0,a.jsx)(c,Object.assign({},n,e)),(0,a.jsx)(h,Object.assign({},n,e))]})}function u(e){var n=(0,o.default)();return(0,a.jsx)(p,Object.assign({},e,{children:(0,l.v)(e.children)}),String(n))}},14433:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>d,metadata:()=>s,toc:()=>h});const s=JSON.parse('{"id":"contributing/new-api-provider","title":"Adding a New API Provider","description":"Guide for adding new API providers to Llama Stack","source":"@site/docs/contributing/new-api-provider.mdx","sourceDirName":"contributing","slug":"/contributing/new-api-provider","permalink":"/llama-stack/docs/contributing/new-api-provider","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/contributing/new-api-provider.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Adding a New API Provider","description":"Guide for adding new API providers to Llama Stack","sidebar_label":"New API Provider","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Overview","permalink":"/llama-stack/docs/contributing/"},"next":{"title":"New Vector Database","permalink":"/llama-stack/docs/contributing/new-vector-database"}}');var r=i(74848),t=i(28453),l=i(4865),o=i(19365);const d={title:"Adding a New API Provider",description:"Guide for adding new API providers to Llama Stack",sidebar_label:"New API Provider",sidebar_position:2},a=void 0,c={},h=[{value:"Getting Started",id:"getting-started",level:2},{value:"Example Implementations",id:"example-implementations",level:2},{value:"Provider Types: Internal vs External",id:"provider-types-internal-vs-external",level:2},{value:"Inference Provider Patterns",id:"inference-provider-patterns",level:2},{value:"OpenAIMixin",id:"openaimixin",level:3},{value:"Testing Your Provider",id:"testing-your-provider",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Testing Levels",id:"testing-levels",level:3},{value:"Implementation Best Practices",id:"implementation-best-practices",level:2},{value:"Configuration Management",id:"configuration-management",level:3},{value:"Error Handling",id:"error-handling",level:3},{value:"Logging",id:"logging",level:3},{value:"Submitting Your Pull Request",id:"submitting-your-pull-request",level:2},{value:"Pre-submission Checklist",id:"pre-submission-checklist",level:3},{value:"PR Content",id:"pr-content",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"Related Resources",id:"related-resources",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"This guide will walk you through the process of adding a new API provider to Llama Stack."}),"\n",(0,r.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,r.jsx)(n.p,{children:"Before implementing your provider, complete these preparatory steps:"}),"\n",(0,r.jsxs)(l.A,{children:[(0,r.jsxs)(o.default,{value:"planning",label:"Planning",children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"1. Review Core Concepts"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Study the ",(0,r.jsx)(n.a,{href:"/docs/concepts",children:"core concepts"})," of Llama Stack"]}),"\n",(0,r.jsx)(n.li,{children:"Choose the API your provider belongs to (Inference, Safety, VectorIO, etc.)"}),"\n"]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"2. Determine Provider Type"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Remote providers"}),": Make requests to external services"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inline providers"}),": Execute implementation locally"]}),"\n"]})]}),(0,r.jsxs)(o.default,{value:"implementation",label:"Implementation Steps",children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"3. Add Provider to Registry"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Add your provider to the appropriate registry in ",(0,r.jsx)(n.code,{children:"llama_stack/providers/registry/"})]}),"\n",(0,r.jsx)(n.li,{children:"Specify pip dependencies necessary for your provider"}),"\n"]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"4. Update Distribution Templates"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Update ",(0,r.jsx)(n.code,{children:"build.yaml"})," and ",(0,r.jsx)(n.code,{children:"run.yaml"})," files in ",(0,r.jsx)(n.code,{children:"llama_stack/distributions/"})," if they should include your provider by default"]}),"\n",(0,r.jsxs)(n.li,{children:["Run ",(0,r.jsx)(n.code,{children:"./scripts/distro_codegen.py"})," if necessary"]}),"\n"]}),(0,r.jsx)(n.admonition,{title:"Distribution Compatibility",type:"note",children:(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"distro_codegen.py"})," will fail if the new provider causes any distribution template to attempt to import provider-specific dependencies. The distribution's ",(0,r.jsx)(n.code,{children:"get_distribution_template()"})," code path should only import Config or model alias definitions from each provider, not the provider's actual implementation."]})})]})]}),"\n",(0,r.jsx)(n.h2,{id:"example-implementations",children:"Example Implementations"}),"\n",(0,r.jsx)(n.p,{children:"Study these example PRs to understand the implementation patterns:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack/pull/609",children:"Grok Inference Implementation"})})," - OpenAI-compatible inference provider"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack/pull/355",children:"Nvidia Inference Implementation"})})," - Remote inference service integration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack/pull/665",children:"Model Context Protocol Tool Runtime"})})," - Tool runtime provider"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"provider-types-internal-vs-external",children:"Provider Types: Internal vs External"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Type"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Internal (In-tree)"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"External (Out-of-tree)"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Description"})}),(0,r.jsx)(n.td,{children:"Provider directly in Llama Stack code"}),(0,r.jsx)(n.td,{children:"Provider outside core codebase but accessible by Llama Stack"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Benefits"})}),(0,r.jsx)(n.td,{children:"Minimal configuration, direct integration"}),(0,r.jsx)(n.td,{children:"Separate provider code, no core changes needed"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Use Cases"})}),(0,r.jsx)(n.td,{children:"Core functionality, widely-used services"}),(0,r.jsx)(n.td,{children:"Specialized services, experimental providers"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"inference-provider-patterns",children:"Inference Provider Patterns"}),"\n",(0,r.jsx)(n.p,{children:"When implementing Inference providers for OpenAI-compatible APIs, Llama Stack provides mixin classes to simplify development."}),"\n",(0,r.jsx)(n.h3,{id:"openaimixin",children:"OpenAIMixin"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"OpenAIMixin"})," class provides OpenAI API functionality for providers that work with OpenAI-compatible endpoints."]}),"\n",(0,r.jsxs)(l.A,{children:[(0,r.jsxs)(o.default,{value:"features",label:"Features",children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Direct API Methods:"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"openai_completion()"}),": Legacy text completion API with full parameter support"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"openai_chat_completion()"}),": Chat completion API supporting streaming, tools, and function calling"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"openai_embeddings()"}),": Text embeddings generation with customizable encoding and dimensions"]}),"\n"]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Model Management:"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"check_model_availability()"}),": Queries the API endpoint to verify model existence and accessibility"]}),"\n"]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Client Management:"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"client"})," property: Automatically creates and configures AsyncOpenAI client instances using your provider's credentials"]}),"\n"]})]}),(0,r.jsxs)(o.default,{value:"implementation",label:"Implementation",children:[(0,r.jsxs)(n.p,{children:["To use ",(0,r.jsx)(n.code,{children:"OpenAIMixin"}),", your provider must implement these abstract methods:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from abc import abstractmethod\n\nclass YourProvider(OpenAIMixin):\n    @abstractmethod\n    def get_api_key(self) -> str:\n        """Return the API key for authentication"""\n        pass\n\n    @abstractmethod\n    def get_base_url(self) -> str:\n        """Return the OpenAI-compatible API base URL"""\n        pass\n\n    # Your provider-specific implementation\n    async def completion(self, request):\n        return await self.openai_completion(request)\n\n    async def chat_completion(self, request):\n        return await self.openai_chat_completion(request)\n'})})]})]}),"\n",(0,r.jsx)(n.h2,{id:"testing-your-provider",children:"Testing Your Provider"}),"\n",(0,r.jsx)(n.p,{children:"Comprehensive testing ensures your provider works correctly across different scenarios."}),"\n",(0,r.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(n.p,{children:"Install required dependencies for your provider:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"llama stack build --distro <your-distribution>\n"})}),"\n",(0,r.jsx)(n.h3,{id:"testing-levels",children:"Testing Levels"}),"\n",(0,r.jsxs)(l.A,{children:[(0,r.jsxs)(o.default,{value:"integration",label:"Integration Testing",children:[(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Location:"})," ",(0,r.jsx)(n.code,{children:"tests/integration/"})]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Purpose:"})," Test functionality using python client-SDK APIs from the ",(0,r.jsx)(n.code,{children:"llama_stack_client"})," package."]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Configuration:"})," Each provider's ",(0,r.jsx)(n.code,{children:"sample_run_config()"})," method references environment variables for API keys. Set these in the environment or pass via the ",(0,r.jsx)(n.code,{children:"--env"})," flag."]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Running Tests:"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Set environment variables\nexport YOUR_PROVIDER_API_KEY=your-key-here\n\n# Run integration tests\nuv run --group test pytest tests/integration/ --stack-config=<your-config>\n"})}),(0,r.jsxs)(n.p,{children:["For details, see ",(0,r.jsx)(n.code,{children:"tests/integration/README.md"}),"."]})]}),(0,r.jsxs)(o.default,{value:"unit",label:"Unit Testing",children:[(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Location:"})," ",(0,r.jsx)(n.code,{children:"tests/unit/providers/"})]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Purpose:"})," Fast, isolated testing of provider components."]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Running Tests:"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"uv run --group unit pytest tests/unit/providers/\n"})}),(0,r.jsxs)(n.p,{children:["These tests run automatically as part of the CI process. For details, see ",(0,r.jsx)(n.code,{children:"tests/unit/README.md"}),"."]})]}),(0,r.jsxs)(o.default,{value:"e2e",label:"End-to-End Testing",children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Manual Validation:"})}),(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Start Llama Stack Server"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"llama stack run <your-distribution>\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Test with Client Scripts"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use existing client scripts in ",(0,r.jsx)(n.a,{href:"https://github.com/meta-llama/llama-stack-apps/tree/main",children:"llama-stack-apps"})]}),"\n",(0,r.jsx)(n.li,{children:"Verify compatibility with your provider"}),"\n",(0,r.jsx)(n.li,{children:"Document which scripts work with your provider"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Validate Core Functionality"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Test all supported API methods"}),"\n",(0,r.jsx)(n.li,{children:"Verify error handling and edge cases"}),"\n",(0,r.jsx)(n.li,{children:"Confirm streaming behavior (if applicable)"}),"\n"]}),"\n"]}),"\n"]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"implementation-best-practices",children:"Implementation Best Practices"}),"\n",(0,r.jsx)(n.h3,{id:"configuration-management",children:"Configuration Management"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from pydantic import BaseModel, Field\n\nclass YourProviderConfig(BaseModel):\n    api_key: str = Field(\n        description="API key for authentication with your service"\n    )\n    base_url: str = Field(\n        default="https://api.yourservice.com/v1",\n        description="Base URL for the API endpoint"\n    )\n    timeout: int = Field(\n        default=30,\n        description="Request timeout in seconds"\n    )\n'})}),"\n",(0,r.jsx)(n.h3,{id:"error-handling",children:"Error Handling"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from llama_stack.apis.common.errors import ProviderError\n\nasync def your_api_method(self, request):\n    try:\n        response = await self.client.your_api_call(request)\n        return response\n    except Exception as e:\n        raise ProviderError(f"Failed to call your API: {str(e)}")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"logging",children:"Logging"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import logging\n\nlogger = logging.getLogger(__name__)\n\nclass YourProvider:\n    async def your_method(self, request):\n        logger.debug(f"Processing request: {request}")\n        # Implementation\n        logger.info("Request processed successfully")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"submitting-your-pull-request",children:"Submitting Your Pull Request"}),"\n",(0,r.jsx)(n.h3,{id:"pre-submission-checklist",children:"Pre-submission Checklist"}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,r.jsx)(n.strong,{children:"All tests pass"})," - Both unit and integration tests"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,r.jsx)(n.strong,{children:"Code follows style guidelines"})," - Pre-commit hooks pass"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,r.jsx)(n.strong,{children:"Documentation updated"})," - Provider configuration documented"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,r.jsx)(n.strong,{children:"Distribution templates updated"})," - If provider should be included by default"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,r.jsx)(n.strong,{children:"Example usage provided"})," - Working example in PR description"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"pr-content",children:"PR Content"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Include in your PR:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Comprehensive test plan"})," describing:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Test scenarios covered"}),"\n",(0,r.jsx)(n.li,{children:"Any manual testing performed"}),"\n",(0,r.jsx)(n.li,{children:"Compatibility with existing client scripts"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Documentation updates"})," including:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Provider configuration options"}),"\n",(0,r.jsx)(n.li,{children:"Environment variables required"}),"\n",(0,r.jsx)(n.li,{children:"Known limitations or considerations"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example configuration"})," showing:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"How to configure your provider"}),"\n",(0,r.jsx)(n.li,{children:"Sample API keys or endpoints (redacted)"}),"\n",(0,r.jsx)(n.li,{children:"Integration with distributions"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Import Errors:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ensure dependencies are properly listed in registry"}),"\n",(0,r.jsx)(n.li,{children:"Check that distribution templates don't import implementation code directly"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Test Failures:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Verify API keys and environment variables are set correctly"}),"\n",(0,r.jsxs)(n.li,{children:["Check that your provider's ",(0,r.jsx)(n.code,{children:"sample_run_config()"})," method is properly implemented"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Configuration Issues:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ensure Pydantic models have proper ",(0,r.jsx)(n.code,{children:"description"})," fields"]}),"\n",(0,r.jsx)(n.li,{children:"Verify that configuration validation works as expected"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/concepts",children:"Core Concepts"})})," - Understanding Llama Stack architecture"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/providers/external",children:"External Providers"})})," - Alternative implementation approach"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"./new-vector-database",children:"Vector Database Guide"})})," - Specialized provider implementation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"./testing-record-replay",children:"Testing Record-Replay"})})," - Advanced testing techniques"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}}}]);