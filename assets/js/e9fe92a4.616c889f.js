"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2496],{73490:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"concepts/architecture","title":"Llama Stack Architecture","description":"Understanding Llama Stack\'s service-oriented design and benefits","source":"@site/docs/concepts/architecture.mdx","sourceDirName":"concepts","slug":"/concepts/architecture","permalink":"/llama-stack/docs/concepts/architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/concepts/architecture.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Llama Stack Architecture","description":"Understanding Llama Stack\'s service-oriented design and benefits","sidebar_label":"Architecture","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Overview","permalink":"/llama-stack/docs/concepts/"},"next":{"title":"APIs","permalink":"/llama-stack/docs/concepts/apis"}}');var r=i(74848),t=i(28453);const l={title:"Llama Stack Architecture",description:"Understanding Llama Stack's service-oriented design and benefits",sidebar_label:"Architecture",sidebar_position:2},a="Llama Stack architecture",c={},o=[{value:"Benefits of Llama stack",id:"benefits-of-llama-stack",level:2},{value:"Current challenges in custom AI applications",id:"current-challenges-in-custom-ai-applications",level:3},{value:"Our Solution: A Universal Stack",id:"our-solution-a-universal-stack",level:3},{value:"Our Philosophy",id:"our-philosophy",level:2}];function d(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"llama-stack-architecture",children:"Llama Stack architecture"})}),"\n",(0,r.jsx)(n.p,{children:"Llama Stack allows you to build different layers of distributions for your AI workloads using various SDKs and API providers."}),"\n",(0,r.jsx)("img",{src:"/img/llama-stack.png",alt:"Llama Stack",width:"400"}),"\n",(0,r.jsx)(n.h2,{id:"benefits-of-llama-stack",children:"Benefits of Llama stack"}),"\n",(0,r.jsx)(n.h3,{id:"current-challenges-in-custom-ai-applications",children:"Current challenges in custom AI applications"}),"\n",(0,r.jsx)(n.p,{children:"Building production AI applications today requires solving multiple challenges:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Infrastructure Complexity"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Running large language models efficiently requires specialized infrastructure."}),"\n",(0,r.jsx)(n.li,{children:"Different deployment scenarios (local development, cloud, edge) need different solutions."}),"\n",(0,r.jsx)(n.li,{children:"Moving from development to production often requires significant rework."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Essential Capabilities"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Safety guardrails and content filtering are necessary in an enterprise setting."}),"\n",(0,r.jsx)(n.li,{children:"Just model inference is not enough - Knowledge retrieval and RAG capabilities are required."}),"\n",(0,r.jsx)(n.li,{children:"Nearly any application needs composable multi-step workflows."}),"\n",(0,r.jsx)(n.li,{children:"Without monitoring, observability and evaluation, you end up operating in the dark."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Lack of Flexibility and Choice"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Directly integrating with multiple providers creates tight coupling."}),"\n",(0,r.jsx)(n.li,{children:"Different providers have different APIs and abstractions."}),"\n",(0,r.jsx)(n.li,{children:"Changing providers requires significant code changes."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"our-solution-a-universal-stack",children:"Our Solution: A Universal Stack"}),"\n",(0,r.jsx)(n.p,{children:"Llama Stack addresses these challenges through a service-oriented, API-first approach:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Develop Anywhere, Deploy Everywhere"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Start locally with CPU-only setups"}),"\n",(0,r.jsx)(n.li,{children:"Move to GPU acceleration when needed"}),"\n",(0,r.jsx)(n.li,{children:"Deploy to cloud or edge without code changes"}),"\n",(0,r.jsx)(n.li,{children:"Same APIs and developer experience everywhere"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Production-Ready Building Blocks"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pre-built safety guardrails and content filtering"}),"\n",(0,r.jsx)(n.li,{children:"Built-in RAG and agent capabilities"}),"\n",(0,r.jsx)(n.li,{children:"Comprehensive evaluation toolkit"}),"\n",(0,r.jsx)(n.li,{children:"Full observability and monitoring"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"True Provider Independence"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Swap providers without application changes"}),"\n",(0,r.jsx)(n.li,{children:"Mix and match best-in-class implementations"}),"\n",(0,r.jsx)(n.li,{children:"Federation and fallback support"}),"\n",(0,r.jsx)(n.li,{children:"No vendor lock-in"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Robust Ecosystem"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Llama Stack is already integrated with distribution partners (cloud providers, hardware vendors, and AI-focused companies)."}),"\n",(0,r.jsx)(n.li,{children:"Ecosystem offers tailored infrastructure, software, and services for deploying a variety of models."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"our-philosophy",children:"Our Philosophy"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Service-Oriented"}),": REST APIs enforce clean interfaces and enable seamless transitions across different environments."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Composability"}),": Every component is independent but works together seamlessly"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Production Ready"}),": Built for real-world applications, not just demos"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Turnkey Solutions"}),": Easy to deploy built in solutions for popular deployment scenarios"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"With Llama Stack, you can focus on building your application while we handle the infrastructure complexity, essential capabilities, and provider integrations."})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);