"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7541],{4865:(e,n,s)=>{s.d(n,{A:()=>u});var t=s(96540),i=s(34164),a=s(23104),o=s(47751),r=s(92303);const l={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=s(74848);function d(e){var n=e.className,s=e.block,t=e.selectedValue,o=e.selectValue,r=e.tabValues,d=[],h=(0,a.a_)().blockElementScrollPositionUntilNextRender,p=function(e){var n=e.currentTarget,s=d.indexOf(n),i=r[s].value;i!==t&&(h(n),o(i))},u=function(e){var n,s=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":var t,i=d.indexOf(e.currentTarget)+1;s=null!=(t=d[i])?t:d[0];break;case"ArrowLeft":var a,o=d.indexOf(e.currentTarget)-1;s=null!=(a=d[o])?a:d[d.length-1]}null==(n=s)||n.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":s},n),children:r.map(function(e){var n=e.value,s=e.label,a=e.attributes;return(0,c.jsx)("li",Object.assign({role:"tab",tabIndex:t===n?0:-1,"aria-selected":t===n,ref:function(e){d.push(e)},onKeyDown:u,onClick:p},a,{className:(0,i.A)("tabs__item",l.tabItem,null==a?void 0:a.className,{"tabs__item--active":t===n}),children:null!=s?s:n}),n)})})}function h(e){var n=e.lazy,s=e.children,a=e.selectedValue,o=(Array.isArray(s)?s:[s]).filter(Boolean);if(n){var r=o.find(function(e){return e.props.value===a});return r?(0,t.cloneElement)(r,{className:(0,i.A)("margin-top--md",r.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:o.map(function(e,n){return(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==a})})})}function p(e){var n=(0,o.u)(e);return(0,c.jsxs)("div",{className:(0,i.A)("tabs-container",l.tabList),children:[(0,c.jsx)(d,Object.assign({},n,e)),(0,c.jsx)(h,Object.assign({},n,e))]})}function u(e){var n=(0,r.default)();return(0,c.jsx)(p,Object.assign({},e,{children:(0,o.v)(e.children)}),String(n))}},65700:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>l,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"id":"building-applications/responses-vs-agents","title":"Agents vs OpenAI Responses API","description":"Compare the Agents API and OpenAI Responses API for building AI applications with tool calling capabilities","source":"@site/docs/building-applications/responses-vs-agents.mdx","sourceDirName":"building-applications","slug":"/building-applications/responses-vs-agents","permalink":"/llama-stack/docs/building-applications/responses-vs-agents","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/building-applications/responses-vs-agents.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Agents vs OpenAI Responses API","description":"Compare the Agents API and OpenAI Responses API for building AI applications with tool calling capabilities","sidebar_label":"Agents vs Responses API","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Agent Execution Loop","permalink":"/llama-stack/docs/building-applications/agent-execution-loop"},"next":{"title":"Tools","permalink":"/llama-stack/docs/building-applications/tools"}}');var i=s(74848),a=s(28453),o=s(4865),r=s(19365);const l={title:"Agents vs OpenAI Responses API",description:"Compare the Agents API and OpenAI Responses API for building AI applications with tool calling capabilities",sidebar_label:"Agents vs Responses API",sidebar_position:5},c="Agents vs OpenAI Responses API",d={},h=[{value:"Overview",id:"overview",level:2},{value:"LLS Agents API",id:"lls-agents-api",level:3},{value:"OpenAI Responses API",id:"openai-responses-api",level:3},{value:"Key Differences",id:"key-differences",level:3},{value:"Feature Comparison",id:"feature-comparison",level:2},{value:"Use Case Example: Research with Multiple Search Methods",id:"use-case-example-research-with-multiple-search-methods",level:2},{value:"Session-based Configuration with Safety Shields",id:"session-based-configuration-with-safety-shields",level:3},{value:"Dynamic Per-call Configuration with Branching",id:"dynamic-per-call-configuration-with-branching",level:3},{value:"Use Case Examples",id:"use-case-examples",level:2},{value:"1. Research and Analysis with Safety Controls",id:"1-research-and-analysis-with-safety-controls",level:3},{value:"2. Dynamic Information Gathering with Branching Exploration",id:"2-dynamic-information-gathering-with-branching-exploration",level:3},{value:"3. OpenAI Migration with Advanced Tool Capabilities",id:"3-openai-migration-with-advanced-tool-capabilities",level:3},{value:"4. Educational Programming Tutor",id:"4-educational-programming-tutor",level:3},{value:"5. Advanced Software Debugging Assistant",id:"5-advanced-software-debugging-assistant",level:3},{value:"Decision Framework",id:"decision-framework",level:2},{value:"Choose Agents API when:",id:"choose-agents-api-when",level:3},{value:"Choose Responses API when:",id:"choose-responses-api-when",level:3},{value:"Related Resources",id:"related-resources",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"agents-vs-openai-responses-api",children:"Agents vs OpenAI Responses API"})}),"\n",(0,i.jsxs)(n.p,{children:["Llama Stack (LLS) provides two different APIs for building AI applications with tool calling capabilities: the ",(0,i.jsx)(n.strong,{children:"Agents API"})," and the ",(0,i.jsx)(n.strong,{children:"OpenAI Responses API"}),". While both enable AI systems to use tools, and maintain full conversation history, they serve different use cases and have distinct characteristics."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note:"})," For simple and basic inferencing, you may want to use the ",(0,i.jsx)(n.a,{href:"/docs/providers/openai-compatibility#chat-completions",children:"Chat Completions API"})," directly, before progressing to Agents or Responses API."]})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.h3,{id:"lls-agents-api",children:"LLS Agents API"}),"\n",(0,i.jsx)(n.p,{children:"The Agents API is a full-featured, stateful system designed for complex, multi-turn conversations. It maintains conversation state through persistent sessions identified by a unique session ID. The API supports comprehensive agent lifecycle management, detailed execution tracking, and rich metadata about each interaction through a structured session/turn/step hierarchy. The API can orchestrate multiple tool calls within a single turn."}),"\n",(0,i.jsx)(n.h3,{id:"openai-responses-api",children:"OpenAI Responses API"}),"\n",(0,i.jsxs)(n.p,{children:["The OpenAI Responses API is a full-featured, stateful system designed for complex, multi-turn conversations, with direct compatibility with OpenAI's conversational patterns enhanced by LLama Stack's tool calling capabilities. It maintains conversation state by chaining responses through a ",(0,i.jsx)(n.code,{children:"previous_response_id"}),", allowing interactions to branch or continue from any prior point. Each response can perform multiple tool calls within a single turn."]}),"\n",(0,i.jsx)(n.h3,{id:"key-differences",children:"Key Differences"}),"\n",(0,i.jsxs)(n.p,{children:["The LLS Agents API uses the Chat Completions API on the backend for inference as it's the industry standard for building AI applications and most LLM providers are compatible with this API. For a detailed comparison between Responses and Chat Completions, see ",(0,i.jsx)(n.a,{href:"https://platform.openai.com/docs/guides/responses-vs-chat-completions",children:"OpenAI's documentation"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Additionally, Agents let you specify input/output shields whereas Responses do not (though support is planned). Agents use a linear conversation model referenced by a single session ID. Responses, on the other hand, support branching, where each response can serve as a fork point, and conversations are tracked by the latest response ID. Responses also lets you dynamically choose the model, vector store, files, MCP servers, and more on each inference call, enabling more complex workflows. Agents require a static configuration for these components at the start of the session."}),"\n",(0,i.jsx)(n.p,{children:"Today the Agents and Responses APIs can be used independently depending on the use case. But, it is also productive to treat the APIs as complementary. It is not currently supported, but it is planned for the LLS Agents API to alternatively use the Responses API as its backend instead of the default Chat Completions API, i.e., enabling a combination of the safety features of Agents with the dynamic configuration and branching capabilities of Responses."}),"\n",(0,i.jsx)(n.h2,{id:"feature-comparison",children:"Feature Comparison"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Feature"}),(0,i.jsx)(n.th,{children:"LLS Agents API"}),(0,i.jsx)(n.th,{children:"OpenAI Responses API"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Conversation Management"})}),(0,i.jsx)(n.td,{children:"Linear persistent sessions"}),(0,i.jsx)(n.td,{children:"Can branch from any previous response ID"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Input/Output Safety Shields"})}),(0,i.jsx)(n.td,{children:"Supported"}),(0,i.jsx)(n.td,{children:"Not yet supported"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Per-call Flexibility"})}),(0,i.jsx)(n.td,{children:"Static per-session configuration"}),(0,i.jsx)(n.td,{children:"Dynamic per-call configuration"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"use-case-example-research-with-multiple-search-methods",children:"Use Case Example: Research with Multiple Search Methods"}),"\n",(0,i.jsx)(n.p,{children:"Let's compare how both APIs handle a research task where we need to:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Search for current information and examples"}),"\n",(0,i.jsx)(n.li,{children:"Access different information sources dynamically"}),"\n",(0,i.jsx)(n.li,{children:"Continue the conversation based on search results"}),"\n"]}),"\n",(0,i.jsxs)(o.A,{children:[(0,i.jsxs)(r.default,{value:"agents",label:"Agents API",children:[(0,i.jsx)(n.h3,{id:"session-based-configuration-with-safety-shields",children:"Session-based Configuration with Safety Shields"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Create agent with static session configuration\nagent = Agent(\n    client,\n    model="Llama3.2-3B-Instruct",\n    instructions="You are a helpful coding assistant",\n    tools=[\n        {\n            "name": "builtin::rag/knowledge_search",\n            "args": {"vector_db_ids": ["code_docs"]},\n        },\n        "builtin::code_interpreter",\n    ],\n    input_shields=["llama_guard"],\n    output_shields=["llama_guard"],\n)\n\nsession_id = agent.create_session("code_session")\n\n# First turn: Search and execute\nresponse1 = agent.create_turn(\n    messages=[\n        {\n            "role": "user",\n            "content": "Find examples of sorting algorithms and run a bubble sort on [3,1,4,1,5]",\n        },\n    ],\n    session_id=session_id,\n)\n\n# Continue conversation in same session\nresponse2 = agent.create_turn(\n    messages=[\n        {\n            "role": "user",\n            "content": "Now optimize that code and test it with a larger dataset",\n        },\n    ],\n    session_id=session_id,  # Same session, maintains full context\n)\n\n# Agents API benefits:\n# \u2705 Safety shields protect against malicious code execution\n# \u2705 Session maintains context between code executions\n# \u2705 Consistent tool configuration throughout conversation\nprint(f"First result: {response1.output_message.content}")\nprint(f"Optimization: {response2.output_message.content}")\n'})})]}),(0,i.jsxs)(r.default,{value:"responses",label:"Responses API",children:[(0,i.jsx)(n.h3,{id:"dynamic-per-call-configuration-with-branching",children:"Dynamic Per-call Configuration with Branching"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# First response: Use web search for latest algorithms\nresponse1 = client.responses.create(\n    model="Llama3.2-3B-Instruct",\n    input="Search for the latest efficient sorting algorithms and their performance comparisons",\n    tools=[\n        {\n            "type": "web_search",\n        },\n    ],  # Web search for current information\n)\n\n# Continue conversation: Switch to file search for local docs\nresponse2 = client.responses.create(\n    model="Llama3.2-1B-Instruct",  # Switch to faster model\n    input="Now search my uploaded files for existing sorting implementations",\n    tools=[\n        {  # Using Responses API built-in tools\n            "type": "file_search",\n            "vector_store_ids": ["vs_abc123"],  # Vector store containing uploaded files\n        },\n    ],\n    previous_response_id=response1.id,\n)\n\n# Branch from first response: Try different search approach\nresponse3 = client.responses.create(\n    model="Llama3.2-3B-Instruct",\n    input="Instead, search the web for Python-specific sorting best practices",\n    tools=[{"type": "web_search"}],  # Different web search query\n    previous_response_id=response1.id,  # Branch from response1\n)\n\n# Responses API benefits:\n# \u2705 Dynamic tool switching (web search \u2194 file search per call)\n# \u2705 OpenAI-compatible tool patterns (web_search, file_search)\n# \u2705 Branch conversations to explore different information sources\n# \u2705 Model flexibility per search type\nprint(f"Web search results: {response1.output_message.content}")\nprint(f"File search results: {response2.output_message.content}")\nprint(f"Alternative web search: {response3.output_message.content}")\n'})})]})]}),"\n",(0,i.jsx)(n.p,{children:"Both APIs demonstrate distinct strengths that make them valuable on their own for different scenarios. The Agents API excels in providing structured, safety-conscious workflows with persistent session management, while the Responses API offers flexibility through dynamic configuration and OpenAI compatible tool patterns."}),"\n",(0,i.jsx)(n.h2,{id:"use-case-examples",children:"Use Case Examples"}),"\n",(0,i.jsx)(n.h3,{id:"1-research-and-analysis-with-safety-controls",children:"1. Research and Analysis with Safety Controls"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Choice: Agents API"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Scenario:"})," You're building a research assistant for a financial institution that needs to analyze market data, execute code to process financial models, and search through internal compliance documents. The system must ensure all interactions are logged for regulatory compliance and protected by safety shields to prevent malicious code execution or data leaks."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why Agents API?"})," The Agents API provides persistent session management for iterative research workflows, built-in safety shields to protect against malicious code in financial models, and structured execution logs (session/turn/step) required for regulatory compliance. The static tool configuration ensures consistent access to your knowledge base and code interpreter throughout the entire research session."]}),"\n",(0,i.jsx)(n.h3,{id:"2-dynamic-information-gathering-with-branching-exploration",children:"2. Dynamic Information Gathering with Branching Exploration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Choice: Responses API"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Scenario:"})," You're building a competitive intelligence tool that helps businesses research market trends. Users need to dynamically switch between web search for current market data and file search through uploaded industry reports. They also want to branch conversations to explore different market segments simultaneously and experiment with different models for various analysis types."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why Responses API?"})," The Responses API's branching capability lets users explore multiple market segments from any research point. Dynamic per-call configuration allows switching between web search and file search as needed, while experimenting with different models (faster models for quick searches, more powerful models for deep analysis). The OpenAI-compatible tool patterns make integration straightforward."]}),"\n",(0,i.jsx)(n.h3,{id:"3-openai-migration-with-advanced-tool-capabilities",children:"3. OpenAI Migration with Advanced Tool Capabilities"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Choice: Responses API"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Scenario:"})," You have an existing application built with OpenAI's Assistants API that uses file search and web search capabilities. You want to migrate to Llama Stack for better performance and cost control while maintaining the same tool calling patterns and adding new capabilities like dynamic vector store selection."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why Responses API?"})," The Responses API provides full OpenAI tool compatibility (",(0,i.jsx)(n.code,{children:"web_search"}),", ",(0,i.jsx)(n.code,{children:"file_search"}),") with identical syntax, making migration seamless. The dynamic per-call configuration enables advanced features like switching vector stores per query or changing models based on query complexity - capabilities that extend beyond basic OpenAI functionality while maintaining compatibility."]}),"\n",(0,i.jsx)(n.h3,{id:"4-educational-programming-tutor",children:"4. Educational Programming Tutor"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Choice: Agents API"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Scenario:"})," You're building a programming tutor that maintains student context across multiple sessions, safely executes code exercises, and tracks learning progress with audit trails for educators."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why Agents API?"})," Persistent sessions remember student progress across multiple interactions, safety shields prevent malicious code execution while allowing legitimate programming exercises, and structured execution logs help educators track learning patterns."]}),"\n",(0,i.jsx)(n.h3,{id:"5-advanced-software-debugging-assistant",children:"5. Advanced Software Debugging Assistant"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Best Choice: Agents API with Responses Backend"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Scenario:"})," You're building a debugging assistant that helps developers troubleshoot complex issues. It needs to maintain context throughout a debugging session, safely execute diagnostic code, switch between different analysis tools dynamically, and branch conversations to explore multiple potential causes simultaneously."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why Agents + Responses?"})," The Agent provides safety shields for code execution and session management for the overall debugging workflow. The underlying Responses API enables dynamic model selection and flexible tool configuration per query, while branching lets you explore different theories (memory leak vs. concurrency issue) from the same debugging point and compare results."]}),"\n",(0,i.jsx)(n.admonition,{title:"Future Enhancement",type:"info",children:(0,i.jsx)(n.p,{children:"The ability to use Responses API as the backend for Agents is not yet implemented but is planned for a future release. Currently, Agents use Chat Completions API as their backend by default."})}),"\n",(0,i.jsx)(n.h2,{id:"decision-framework",children:"Decision Framework"}),"\n",(0,i.jsx)(n.p,{children:"Use this framework to choose the right API for your use case:"}),"\n",(0,i.jsx)(n.h3,{id:"choose-agents-api-when",children:"Choose Agents API when:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\u2705 You need ",(0,i.jsx)(n.strong,{children:"safety shields"})," for input/output validation"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 Your application requires ",(0,i.jsx)(n.strong,{children:"linear conversation flow"})," with persistent context"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 You need ",(0,i.jsx)(n.strong,{children:"audit trails"})," and structured execution logs"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 Your tool configuration is ",(0,i.jsx)(n.strong,{children:"static"})," throughout the session"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 You're building ",(0,i.jsx)(n.strong,{children:"educational, financial, or enterprise"})," applications with compliance requirements"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"choose-responses-api-when",children:"Choose Responses API when:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\u2705 You need ",(0,i.jsx)(n.strong,{children:"conversation branching"})," to explore multiple paths"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 You want ",(0,i.jsx)(n.strong,{children:"dynamic per-call configuration"})," (models, tools, vector stores)"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 You're ",(0,i.jsx)(n.strong,{children:"migrating from OpenAI"})," and want familiar tool patterns"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 You need ",(0,i.jsx)(n.strong,{children:"OpenAI compatibility"})," for existing workflows"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 Your application benefits from ",(0,i.jsx)(n.strong,{children:"flexible, experimental"})," interactions"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./agent",children:"Agents"})})," - Understanding the Agents API fundamentals"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./agent-execution-loop",children:"Agent Execution Loop"})})," - How agents process turns and steps"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./tools",children:"Tools Integration"})})," - Adding capabilities to both APIs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/docs/providers/openai-compatibility",children:"OpenAI Compatibility"})})," - Using OpenAI-compatible endpoints"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./safety",children:"Safety Guardrails"})})," - Implementing safety measures in agents"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}}}]);