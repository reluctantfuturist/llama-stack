"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5586],{4865:(e,n,t)=>{t.d(n,{A:()=>p});var s=t(96540),i=t(34164),o=t(23104),a=t(47751),r=t(92303);const l={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=t(74848);function d(e){var n=e.className,t=e.block,s=e.selectedValue,a=e.selectValue,r=e.tabValues,d=[],u=(0,o.a_)().blockElementScrollPositionUntilNextRender,h=function(e){var n=e.currentTarget,t=d.indexOf(n),i=r[t].value;i!==s&&(u(n),a(i))},p=function(e){var n,t=null;switch(e.key){case"Enter":h(e);break;case"ArrowRight":var s,i=d.indexOf(e.currentTarget)+1;t=null!=(s=d[i])?s:d[0];break;case"ArrowLeft":var o,a=d.indexOf(e.currentTarget)-1;t=null!=(o=d[a])?o:d[d.length-1]}null==(n=t)||n.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":t},n),children:r.map(function(e){var n=e.value,t=e.label,o=e.attributes;return(0,c.jsx)("li",Object.assign({role:"tab",tabIndex:s===n?0:-1,"aria-selected":s===n,ref:function(e){d.push(e)},onKeyDown:p,onClick:h},o,{className:(0,i.A)("tabs__item",l.tabItem,null==o?void 0:o.className,{"tabs__item--active":s===n}),children:null!=t?t:n}),n)})})}function u(e){var n=e.lazy,t=e.children,o=e.selectedValue,a=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){var r=a.find(function(e){return e.props.value===o});return r?(0,s.cloneElement)(r,{className:(0,i.A)("margin-top--md",r.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:a.map(function(e,n){return(0,s.cloneElement)(e,{key:n,hidden:e.props.value!==o})})})}function h(e){var n=(0,a.u)(e);return(0,c.jsxs)("div",{className:(0,i.A)("tabs-container",l.tabList),children:[(0,c.jsx)(d,Object.assign({},n,e)),(0,c.jsx)(u,Object.assign({},n,e))]})}function p(e){var n=(0,r.default)();return(0,c.jsx)(h,Object.assign({},e,{children:(0,a.v)(e.children)}),String(n))}},17876:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>p,frontMatter:()=>l,metadata:()=>s,toc:()=>u});const s=JSON.parse('{"id":"building-applications/agent-execution-loop","title":"Agent Execution Loop","description":"Understanding the internal processing flow of Llama Stack agents","source":"@site/docs/building-applications/agent-execution-loop.mdx","sourceDirName":"building-applications","slug":"/building-applications/agent-execution-loop","permalink":"/docs/building-applications/agent-execution-loop","draft":false,"unlisted":false,"editUrl":"https://github.com/meta-llama/llama-stack/tree/main/docs/docs/building-applications/agent-execution-loop.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Agent Execution Loop","description":"Understanding the internal processing flow of Llama Stack agents","sidebar_label":"Agent Execution Loop","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Agents","permalink":"/docs/building-applications/agent"},"next":{"title":"Agents vs Responses API","permalink":"/docs/building-applications/responses-vs-agents"}}');var i=t(74848),o=t(28453),a=t(4865),r=t(19365);const l={title:"Agent Execution Loop",description:"Understanding the internal processing flow of Llama Stack agents",sidebar_label:"Agent Execution Loop",sidebar_position:4},c="Agent Execution Loop",d={},u=[{value:"Steps in the Agent Workflow",id:"steps-in-the-agent-workflow",level:2},{value:"Execution Flow Diagram",id:"execution-flow-diagram",level:2},{value:"Agent Execution Example",id:"agent-execution-example",level:2},{value:"Key Configuration Options",id:"key-configuration-options",level:2},{value:"Loop Control",id:"loop-control",level:3},{value:"Safety Configuration",id:"safety-configuration",level:3},{value:"Tool Integration",id:"tool-integration",level:3},{value:"Related Resources",id:"related-resources",level:2}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"agent-execution-loop",children:"Agent Execution Loop"})}),"\n",(0,i.jsx)(n.p,{children:"Agents are the heart of Llama Stack applications. They combine inference, memory, safety, and tool usage into coherent workflows. At its core, an agent follows a sophisticated execution loop that enables multi-step reasoning, tool usage, and safety checks."}),"\n",(0,i.jsx)(n.h2,{id:"steps-in-the-agent-workflow",children:"Steps in the Agent Workflow"}),"\n",(0,i.jsx)(n.p,{children:"Each agent turn follows these key steps:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Initial Safety Check"}),": The user's input is first screened through configured safety shields"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Context Retrieval"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["If RAG is enabled, the agent can choose to query relevant documents from memory banks. You can use the ",(0,i.jsx)(n.code,{children:"instructions"})," field to steer the agent."]}),"\n",(0,i.jsx)(n.li,{children:"For new documents, they are first inserted into the memory bank."}),"\n",(0,i.jsx)(n.li,{children:"Retrieved context is provided to the LLM as a tool response in the message history."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Inference Loop"}),": The agent enters its main execution loop:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"The LLM receives a user prompt (with previous tool outputs)"}),"\n",(0,i.jsxs)(n.li,{children:["The LLM generates a response, potentially with ",(0,i.jsx)(n.a,{href:"./tools",children:"tool calls"})]}),"\n",(0,i.jsxs)(n.li,{children:["If tool calls are present:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Tool inputs are safety-checked"}),"\n",(0,i.jsx)(n.li,{children:"Tools are executed (e.g., web search, code execution)"}),"\n",(0,i.jsx)(n.li,{children:"Tool responses are fed back to the LLM for synthesis"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["The loop continues until:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"The LLM provides a final response without tool calls"}),"\n",(0,i.jsx)(n.li,{children:"Maximum iterations are reached"}),"\n",(0,i.jsx)(n.li,{children:"Token limit is exceeded"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Final Safety Check"}),": The agent's final response is screened through safety shields"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"execution-flow-diagram",children:"Execution Flow Diagram"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"sequenceDiagram\n    participant U as User\n    participant E as Executor\n    participant M as Memory Bank\n    participant L as LLM\n    participant T as Tools\n    participant S as Safety Shield\n\n    Note over U,S: Agent Turn Start\n    U->>S: 1. Submit Prompt\n    activate S\n    S->>E: Input Safety Check\n    deactivate S\n\n    loop Inference Loop\n        E->>L: 2.1 Augment with Context\n        L--\x3e>E: 2.2 Response (with/without tool calls)\n\n        alt Has Tool Calls\n            E->>S: Check Tool Input\n            S->>T: 3.1 Execute Tool\n            T--\x3e>E: 3.2 Tool Response\n            E->>L: 4.1 Tool Response\n            L--\x3e>E: 4.2 Synthesized Response\n        end\n\n        opt Stop Conditions\n            Note over E: Break if:\n            Note over E: - No tool calls\n            Note over E: - Max iterations reached\n            Note over E: - Token limit exceeded\n        end\n    end\n\n    E->>S: Output Safety Check\n    S->>U: 5. Final Response\n"})}),"\n",(0,i.jsx)(n.p,{children:"Each step in this process can be monitored and controlled through configurations."}),"\n",(0,i.jsx)(n.h2,{id:"agent-execution-example",children:"Agent Execution Example"}),"\n",(0,i.jsx)(n.p,{children:"Here's an example that demonstrates monitoring the agent's execution:"}),"\n",(0,i.jsxs)(a.A,{children:[(0,i.jsx)(r.default,{value:"streaming",label:"Streaming Execution",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from llama_stack_client import LlamaStackClient, Agent, AgentEventLogger\n\n# Replace host and port\nclient = LlamaStackClient(base_url=f"http://{HOST}:{PORT}")\n\nagent = Agent(\n    client,\n    # Check with `llama-stack-client models list`\n    model="Llama3.2-3B-Instruct",\n    instructions="You are a helpful assistant",\n    # Enable both RAG and tool usage\n    tools=[\n        {\n            "name": "builtin::rag/knowledge_search",\n            "args": {"vector_db_ids": ["my_docs"]},\n        },\n        "builtin::code_interpreter",\n    ],\n    # Configure safety (optional)\n    input_shields=["llama_guard"],\n    output_shields=["llama_guard"],\n    # Control the inference loop\n    max_infer_iters=5,\n    sampling_params={\n        "strategy": {"type": "top_p", "temperature": 0.7, "top_p": 0.95},\n        "max_tokens": 2048,\n    },\n)\nsession_id = agent.create_session("monitored_session")\n\n# Stream the agent\'s execution steps\nresponse = agent.create_turn(\n    messages=[{"role": "user", "content": "Analyze this code and run it"}],\n    documents=[\n        {\n            "content": "https://raw.githubusercontent.com/example/code.py",\n            "mime_type": "text/plain",\n        }\n    ],\n    session_id=session_id,\n)\n\n# Monitor each step of execution\nfor log in AgentEventLogger().log(response):\n    log.print()\n'})})}),(0,i.jsx)(r.default,{value:"non-streaming",label:"Non-Streaming Execution",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from rich.pretty import pprint\n\n# Using non-streaming API, the response contains input, steps, and output.\nresponse = agent.create_turn(\n    messages=[{"role": "user", "content": "Analyze this code and run it"}],\n    documents=[\n        {\n            "content": "https://raw.githubusercontent.com/example/code.py",\n            "mime_type": "text/plain",\n        }\n    ],\n    session_id=session_id,\n    stream=False,\n)\n\npprint(f"Input: {response.input_messages}")\npprint(f"Output: {response.output_message.content}")\npprint(f"Steps: {response.steps}")\n'})})})]}),"\n",(0,i.jsx)(n.h2,{id:"key-configuration-options",children:"Key Configuration Options"}),"\n",(0,i.jsx)(n.h3,{id:"loop-control",children:"Loop Control"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"max_infer_iters"}),": Maximum number of inference iterations (default: 5)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"max_tokens"}),": Token limit for responses"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"temperature"}),": Controls response randomness"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"safety-configuration",children:"Safety Configuration"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"input_shields"}),": Safety checks for user input"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"output_shields"}),": Safety checks for agent responses"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"tool-integration",children:"Tool Integration"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"tools"}),": List of available tools for the agent"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"tool_choice"}),": Control over when tools are used"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./agent",children:"Agents"})})," - Understanding agent fundamentals"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./tools",children:"Tools Integration"})})," - Adding capabilities to agents"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./safety",children:"Safety Guardrails"})})," - Implementing safety measures"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"./rag",children:"RAG (Retrieval Augmented Generation)"})})," - Building knowledge-enhanced workflows"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);